---
title: 知识追踪模型调研
tags:
  - 知识追踪
categories:
  - 论文阅读
date: 2019-05-21 22:22:00
toc: true
mathjax: true

---

## 一、前言
知识追踪是构建自适应系统的关键。在自适应系统中，无论是做习题路径规划，推荐，还是后期的知识图谱，都需准确评估学生的知识点掌握情况。从[历年提交论文](http://www.arxiv-sanity.com/search?q=Knowledge+Tracing)来看，知识追踪领域相关的研究依次经历了以下几个阶段：

  - IRT（Item response theory）  项目反应理论
  - PFA评估模型
  - BKT（Bayesin knowledge tracing） 基于贝叶斯网络的学生知识点追踪模型
  - DKT(Deep konwledge traing)  基于深度神经网络的学生知识点追踪模型
  - DKT+（针对DKT模型的缺点提出的增强模型）
  - DKVMN(Dynamic Key-Value Memory Networks for Knowledge Tracing)知识追踪场景下的动态key-value记忆网络
  - DKVMN+（针对DKVMN模型的缺点提出的增强模型）
  - Deep-IRT（IRT+DKVMN）

本文意在通过以上论文，分析知识追踪在教学的技术可行性，思考怎么帮助学生摒弃题海战术，高效精准提升。

<!-- more -->


---


## 二、模型
### 1、IRT
IRT-项目反应理论
IRT 简单来说就是通过让被测试者做题来 **区分 **被测试者的 **能力层次**（比如很低、低、中等、高、很高等）。
通过模型的发展史与模型公式，可以了解到模型无法进一步精确获取每个知识点的掌握情况，只能粗略得到被测试者的能力层次，因此此算法不做深入了解。

### 2、BKT
BKT-贝叶斯知识追踪模型
深度学习未突破前，BKT是知识追踪最常用的一个模型，是含有隐变量的马尔可夫模型（HMM）
BKT通过对学生的每个知识点单独建模来了解学生特定知识点的掌握情况（模型无法表示知识点间的相关性）。

**模型简介**
如下图，是BKT的一个模型，以及对应的4个主要参数，L0，T，G，S。模型需要根据学生以往的历史答题系列情况学习出这4个对应的参数。BKT是对不同的的知识点单独进行建模的，理论上来说，训练数据有多少个知识点，就有多少组对应的（L0，T,G,S）参数。

模型用一个二元组 {掌握该知识点，没掌握该知识点} 来表示学生某个知识的掌握状态，并假设知识一旦掌握就不会被遗忘。模型还有个stop_policy准则，比如一旦某个知识点的掌握概率达到0.95，就假定学生已经学会了这项技能。导师凭此阈值来确定何时不再要求学生回答特定技能的问题。

- L0：表示学生的未开始做这道题目时，或者为开始连续这项知识点的时候，他的一个掌握程度如何（即掌握这个知识点的概率是多少），这个一般我们可以从训练数据里面求平均值获得，也可以使用经验，比如一般来说掌握的程度是对半概率，那么L0=0.5
- T ：表示学生经过做题练习后，知识点从不会到学会的概率
- G：表示学生没掌握这项知识点，但是还是蒙对的概率
- S：表示学生实际上掌握了这项知识点，但是还是给做错了的概率

![](https://hexo-blog-wasim.oss-cn-shenzhen.aliyuncs.com/%E7%9F%A5%E8%AF%86%E8%BF%BD%E8%B8%AA%E8%B0%83%E7%A0%94-1.png)

![](https://hexo-blog-wasim.oss-cn-shenzhen.aliyuncs.com/%E7%9F%A5%E8%AF%86%E8%BF%BD%E8%B8%AA%E8%B0%83%E7%A0%94-9.png)
 
其实可以发现，这样模型构造还是非常简单的，模型只是只是简单的针对知识点进行训练，所有的学生都是用的同一个模型。但是学生有好有坏，因此可以加个节点，不同的学生使用不同的L0。另外题目的难度也是可以应用到模型的，比如难度系数大的 G S参数就可以不一样。根据难度系数训练多组G S。

**优缺点**
但是就算模型引入了学生未掌握知识的情况下猜对题目的概率、学生掌握知识的情况下答错题目的概率、学生的先验知识和问题的难度来扩展模型，依然存在几个问题：
1）学生的知识状态用二元组表示并不是很实际。
2）隐藏状态和练习题之间的映射模糊，很难充分预测每个练习的某个知识点概念
3）观测状态的二元组表示会限制题目的类型


### 3、DKT
DKT-深度神经网络知识追踪模型

**模型简介**
深度神经网络知识追踪模型DKT的结构图：
![](https://hexo-blog-wasim.oss-cn-shenzhen.aliyuncs.com/%E7%9F%A5%E8%AF%86%E8%BF%BD%E8%B8%AA%E8%B0%83%E7%A0%94-2.png)
简单起见，假设题库总共有4道习题，那么首先可以确定的输出层的节点数量为4，对应了各题回答正确的概率。接着，如果我们对输出采用one-hot编码，输入层的节点数就是`题目数量 * 答题结果 = 4 * 2 = 8`个。首先将输入层全连接到RNN的隐层，接着建立隐层到输出层的全连接，最后使用Sigmoid函数作为激活函数，一个基础的DKT模型就构建完毕了。接着为了训练模型，定义如下的损失函数:
![](https://hexo-blog-wasim.oss-cn-shenzhen.aliyuncs.com/%E7%9F%A5%E8%AF%86%E8%BF%BD%E8%B8%AA%E8%B0%83%E7%A0%94-3.png)
其中y是t时刻的模型预测输出，qt+1是t+1时刻用户回答的题目ID（one-hot向量），at+1是t+1时刻的用户答题的对错, ℓ是`binary cross entropy`损失函数。

**优缺点**
很多研究表明DKT模型在各种开源数据集上的表现基本都优于BKT。相关论文表明DKT的优势主要在于：
**1）近因效应**
在当前时间学生的做题结果是会受到近期学生在这些知识点上的表现的影响的，在BKT模型中假定学生一旦掌握某一知识点，对该知识点就不会遗忘，学生在以后做到属于该知识点的题目时往往就会表现很好。而实际上并不是这样的，时间久了，学生也可能会遗忘之前掌握的知识点。而DKT模型能很好的捕捉学生最近的表现来预测学生的做题结果，能更多的利用学生最近的表现。
**2）上下文试验序列**
学生在做题的过程中，可能是多个知识点的题较叉练习，例如学生在知识点A，B 上的做题顺序是A1−B1−A2−B2−A3−B3 。BKT只能在单个知识点建模，无法将学生这样的做题顺序给表述出来。而DKT能针对多个知识点建模，能很好的表述这样的做题顺序。
**3）知识点内在相关性**
实际情况中，知识点互相之间是具有相关性的，如最上面的图所示，X-截距、Y-截距和线性方程等之间都是具有很强的相关性的。BKT由于只能对单个知识点建模，因此无法将这些相关性表示出来。而DKT可以对多个知识点建模，且神经网络可以根据学生的做题结果获得知识点之间的关系。根据知识点内在相关性后期还能构建知识图谱。
**4）个体之间的能力差异**
DKT 能根据该学生在各个知识点上的表现情况来获得学生的平均能力（该能力能一定程度代表学生的学习能力），而BKT 由于只能在单个知识点上建模，因此无法获得学生在各知识点上的平均水平。

DKT当前在学生知识点追踪上获得了良好的表现，然而其依然存在一些不足，主要有两个方面：
**1）模型没法重构当前的输入结果**
**2）在时间序上学生对知识点的掌握度不是连续一致，而是波动的**
针对以上两个问题，18年6月香港科技大学有人提出了DKT增强模型，解决方案： Prediction-Consistent Regularization，详见参考文献。

 
### 4、DKVMN
DKVMN-知识追踪场景下的动态key-value记忆网络

**模型简介**
通常，KT被制定为监督序列学习问题：给定学生过去的练习情况，预测学生正确回答新练习的概率。虽然贝叶斯知识追踪（BKT）可以输出学生对某些预定义概念的掌握程度，但它缺乏提取未定义概念和模拟复杂概念状态转换的能力。深度知识追踪（DKT）利用LSTM来解决BKT的问题，DKT总结了学生在一个隐藏状态下所有概念的知识状态，这使其很难追踪学生掌握了某个概念的多少，而且很难指出学生擅长或不熟悉的概念。而DKVMN具有利用概念之间的关系以及跟踪每个概念状态的能力，它可以自动学习输入练习和基础概念之间的相关性，并为每个概念维护概念状态。在每个时间步，只有相关的状态会更新。

![](https://hexo-blog-wasim.oss-cn-shenzhen.aliyuncs.com/%E7%9F%A5%E8%AF%86%E8%BF%BD%E8%B8%AA%E8%B0%83%E7%A0%94-4.png)

**优缺点**
论文的实验结果：

- DKVMN在四个数据集上实验效果优于BKT,BKT+,DKT,MANNS。
- DKVMN的参数比DKT少。
- 和DKT相比，DKVMN更好的解决了overfitting的问题。
- 能利用不同练习潜在概念间的关系。
- 直接输出学生每个概念的掌握程度。
- 自动发现练习的潜在概念。
- 能描述学生知识状态的变化。


### 5、Deep-IRT
Deep-IRT 是19年4月份的最新研究成果，是IRT与DKVMN的结合体。
![](https://hexo-blog-wasim.oss-cn-shenzhen.aliyuncs.com/%E7%9F%A5%E8%AF%86%E8%BF%BD%E8%B8%AA%E8%B0%83%E7%A0%94-5.png)

---


## 三、结论

诸多文献表明，预测知识点掌握情况相对较好的三个模型为 DKT、DKVMN 和 Deep-IRT，它们在四个基准数据集上的知识点掌握情况预测准确率基本在81%左右徘徊。

**各模型的输入输出：**

![](https://hexo-blog-wasim.oss-cn-shenzhen.aliyuncs.com/20200527174837.png)


**各模型的评测效果：**
  图中的 AUC 越高，预测准确率越高

- AUC = 1，代表完美分类器，准确率100%
- 0.5 < AUC < 1，优于随机分类器
- 0 < AUC < 0.5，差于随机分类器

![](https://hexo-blog-wasim.oss-cn-shenzhen.aliyuncs.com/%E7%9F%A5%E8%AF%86%E8%BF%BD%E8%B8%AA%E8%B0%83%E7%A0%94-6.png)
**图1：模型预测比对**

**各模型的参数比对：****从图2可以发现，DKT虽然结构简单易理解，但是参数过多，会延长训练时间，增大过拟合风险

![](https://hexo-blog-wasim.oss-cn-shenzhen.aliyuncs.com/%E7%9F%A5%E8%AF%86%E8%BF%BD%E8%B8%AA%E8%B0%83%E7%A0%94-7.png)
**图2：模型参数比对**



**综合各个模型的优缺点，考虑到预测效果、参数大小、训练难度、编码难度，模型选择优先级为 DKT 、DKVMN 和 Deep-IRT。**

---


## 四、附录

### 1、AI 论文

- [Individualized Bayesian Knowledge Tracing Models. 2013-07-09]()
- [Deep Knowledge Tracing. 2015-06-19](https://arxiv.org/abs/1506.05908)
- [From Predictive Models to Instructional Policies. 2015-06-26](https://eric.ed.gov/?id=ED560516)
- [Going Deeper with Deep Knowledge Tracing. 2016](http://xueshu.baidu.com/usercenter/paper/show?paperid=3847eccb1d15b68ae57c6e58c484199e&site=xueshu_se)
- [How Deep is Knowledge Tracing? 2016-02-21](https://arxiv.org/pdf/1604.02416.pdf)
- [Dynamic Key-Value Memory Network for Knowledge Tracing. 20170217](https://arxiv.org/abs/1611.08108v1)
- [Addressing Two Problems in Deep Knowledge Tracing via Prediction-Consistent Regularization. 2018-06-06](http://xueshu.baidu.com/usercenter/paper/show?paperid=4ae2ecc40382ea93e4b106d93ef74231&site=xueshu_se)
- [Memory-Augmented Neural Networks for Knowledge Tracing from the Perspective of Learning and Forgetting. 2018-10-01](https://arxiv.org/abs/1805.10768v2)
- [Deep-IRT: Make Deep Learning Based Knowledge Tracing Explainable Using Item Response Theory. 2019-04-26](https://arxiv.org/abs/1904.11738)

### 2、文章

- IRT（项目反应理论）
  - [知乎-如何通俗的理解项目反应理论？](https://www.zhihu.com/question/24671541/answer/151532194)
  - [csdn-项目反应理论模型及公式简介](https://blog.csdn.net/quintind/article/details/78993886)
  - [基于IRT的计算机自适应测评（IRT发展历史、理论介绍、常用模型、优缺点、CAT）](http://blog.sina.com.cn/s/blog_67d8f9c10100wq72.html)
- BKT（贝叶斯知识追踪模型）
  - [BKT模型简介](https://www.cnblogs.com/GuoJiaSheng/p/7099724.html)
- DKT（深度神经网络知识追踪模型）
  - [DKT简介及优缺点比较](https://www.cnblogs.com/jiangxinyang/p/9732447.html)
  - [DKT相关论文解读](https://blog.csdn.net/Zoe_Su/article/details/84481651)
  - [流利说基于 TensorFlow 的自适应系统实践](https://mp.weixin.qq.com/s/HrrAb05PjXRytwLIICMNMw)
  - [扇贝应用 TensorFlow 实现深度知识追踪](https://mp.weixin.qq.com/s/VOEJOWyh9j_XyJMliKpkkw)
- DKVMN（动态key-value记忆网络）
  - [知识追踪场景下的动态key-value记忆网络](https://zhuanlan.zhihu.com/p/55914739)

### 3、项目

- DKT（TensorFlow+Keras）：[https://github.com/Wasim37/Deep-Knowledge-Tracing](https://github.com/Wasim37/Deep-Knowledge-Tracing)
- DKT+（TensorFlow）：[https://github.com/ckyeungac/deep-knowledge-tracing-plus](https://github.com/ckyeungac/deep-knowledge-tracing-plus)
- DKVMN（MXNet）：[https://github.com/Wasim37/DKVMN](https://github.com/Wasim37/DKVMN)
- DKVMN（TensorFlow）：[https://github.com/Wasim37/DKVMN-1](https://github.com/Wasim37/DKVMN-1)

### 4、PDF

- [PDF 阅读工具](https://github.com/elliottzheng/CopyTranslator/blob/master/README_zh.md)
- PDF 链接：https://pan.baidu.com/s/1wf-gbkY3mYrbz9r5K6d8kw  提取码：ynj7

![](https://hexo-blog-wasim.oss-cn-shenzhen.aliyuncs.com/%E7%9F%A5%E8%AF%86%E8%BF%BD%E8%B8%AA%E8%B0%83%E7%A0%94-8.png)

