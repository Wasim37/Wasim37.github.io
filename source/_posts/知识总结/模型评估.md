---
title: 模型评估
tags:
categories:
  - 知识总结
date: 2019-11-2 22:22:00
toc: true
mathjax: true

---

# 模型评估指标
有时候为了更好更快的评估模型，我们需要设置评估指标。常见的评估指标有：准确率/召回率/精准率/F值
1）**准确率(Accuracy)** = 预测正确的样本数/总样本数
2）**召回率(Recall)** = 预测正确的正例样本数/样本中的全部正例样本数
3）**精准率(Precision)** = 预测正确的正例样本数/预测为正例的样本数
4）**F值** = Precision*Recall*2 / (Precision+Recall) (即F值为正确率和召回率的调和平均值)
![](https://hexo-blog-wasim.oss-cn-shenzhen.aliyuncs.com/%E5%9B%9E%E5%BD%92/20180130184513.png)
![](https://hexo-blog-wasim.oss-cn-shenzhen.aliyuncs.com/%E5%9B%9E%E5%BD%92/20180130191216.png)


<!-- more -->
---

# ROC与AUC
**对于分类器，或者说分类算法，评价指标主要有精准率(Precision)，召回率(Recall)，F-score1，以及现在所说的ROC和AUC。**
**ROC、AUC相比准确率、召回率、F-score这样的评价指标，有这样一个很好的特性**：<font color="red">**当测试集中正负样本的分布变化的时候，ROC曲线能够保持不变**</font>。在实际的数据集中经常会出现类不平衡（class imbalance）现象，即负样本比正样本多很多（或者相反），而且测试数据中的正负样本的分布也可能随着时间变化。

ROC曲线的**纵轴是“真正例率”**（True Positive Rate 简称TPR），**横轴是“假正例率”** （False Positive Rate 简称FPR）。
ROC曲线反映了FPR与TPR之间权衡的情况，通俗地来说，即在TPR随着FPR递增的情况下，谁增长得更快，快多少的问题。<font color="red">**TPR增长得越快，曲线越往上屈，AUC就越大，反映了模型的分类性能就越好**</font>。当正负样本不平衡时，这种模型评价方式比起一般的精确度评价方式的好处尤其显著。

![](https://hexo-blog-wasim.oss-cn-shenzhen.aliyuncs.com/%E5%9B%9E%E5%BD%92/20180130192629.png)

**AUC（Area Under Curve）被定义为ROC曲线下的面积**，显然这个面积的数值不会大于1。又由于ROC曲线一般都处于y=x这条直线的上方，所以AUC的取值范围在0.5和1之间。使用AUC值作为评价标准是因为很多时候ROC曲线并不能清晰的说明哪个分类器的效果更好，而AUC作为数值可以直观的评价分类器的好坏，值越大越好。
1）AUC = 1，是完美分类器，采用这个预测模型时，不管设定什么阈值都能得出完美预测。绝大多数预测的场合，不存在完美分类器。
2）0.5 < AUC < 1，优于随机猜测。这个分类器（模型）妥善设定阈值的话，能有预测价值。
3）AUC = 0.5，跟随机猜测一样（例：丢铜板），模型没有预测价值。
4）AUC < 0.5，比随机猜测还差；但只要总是反预测而行，就优于随机猜测。

至于ROC曲线具体是如何画出来的，这里推荐一篇文章：[ROC和AUC介绍以及如何计算AUC](http://alexkong.net/2013/06/introduction-to-auc-and-roc/)

[机器学习和统计里面的auc怎么理解？为什么比accuracy更常用？](https://www.zhihu.com/question/39840928)

---



# 除了MSE，还有哪些模型效果判断方法？区别是什么

- **SSE(The sum of squares due to error)**
和方差、误差平方和。计算的是拟合数据和原始数据对应点的误差的平方和，越趋近于0表示模型越拟合训练数据。
$$SSE=\sum_{t=1}^{N}(observed_t-predicted_t)^2 $$

- **MSE(Mean squared error)：**
均方误差。计算的是预测数据和原始数据对应点误差的平方和的均值，越趋近于0表示模型越拟合训练数据。
$$MSE=\frac{1}{N}\sum_{t=1}^{N}(observed_t-predicted_t)^2 $$

- **RMSE(Root mean squared error)：**
均方根，也叫回归系统的拟合标准差，是MSE的平方根
$$RMSE=\sqrt{\frac{1}{N}\sum_{t=1}^{N}(observed_t-predicted_t)^2}$$

- **MAE(Mean Absolute Error)：**
平均绝对误差是绝对误差的平均值。平均绝对误差能更好地反映预测值误差的实际情况.
$$MAE={\frac{1}{N}\sum_{i=1}^{N}\lvert(observed_t-predicted_t)\rvert}$$

- **RMS(Root Mean Square)：**
均方根值计算方法是先平方、再平均、然后开方，[维基百科定义](https://zh.wikipedia.org/wiki/%E5%B9%B3%E6%96%B9%E5%B9%B3%E5%9D%87%E6%95%B0)

- **SD(standard Deviation)：**
标准差又常称均方差，是方差的算术平方根。标准差能反映一个数据集的离散程度。平均数相同的两组组数据，标准差未必相同。
$$SD=\sqrt{\frac{1}{N}\sum_{i=1}^{N}(x_i-u)^2}$$

- $R^2(R-Squared)$ ：取值范围(负无穷,1]，值越大表示模型越拟合训练数据；最优解是1；
当模型预测为随机值的时候，有可能为负；若预测值恒为样本期望，$R^2$ 为0

Adjusted R-Squared:
$$R_{adj}^2=1-\frac{(n-1)(1-R^2)}{n-p-1}$$

$R^2$ 及其校正函数用处详见第18题：[机器学习笔试题精选](https://mp.weixin.qq.com/s/fqedw0vRzgifVtaVWrk_uw)

- **TSS(Total Sum of Squares)**：总平方和，TSS表示样本之间的差异情况，是伪方差的m倍

- **RSS(Residual Sum of Squares)**：残差平方和，RSS表示预测值和样本值之间的差异情况，是MSE的m倍

---

