---
title: 爬虫、反爬虫、反反爬虫
categories:
  - 其他技术
tags:
  - 爬虫
date: 2016-12-7 18:53:00
toc: false
---

最近用爬虫爬取了大量数据，以下是汇总的相关知识点

### 什么是爬虫和反爬虫
- **爬虫** —— 使用任何技术手段，批量获取网站信息的一种方式。关键在于批量。
- **反爬虫** —— 使用任何技术手段，阻止别人批量获取自己网站信息的一种方式。关键也在于批量。
- **误伤** —— 在反爬虫的过程中，错误的将普通用户识别为爬虫。误伤率高的反爬虫策略，效果再好也不能用。
- **拦截** —— 成功地阻止爬虫访问。通常来说，拦截率越高的策略，误伤率就越高，因此要做权衡。
- **资源** —— 机器成本与人力成本的总和。

---

### 反什么样的爬虫
- **应届毕业生(三月份爬虫)**
三月份爬虫通常和毕业生(本科生、硕士、博士等)有关，他们的爬虫简单粗暴，为了让论文有数据支撑，根本不管服务器压力，加上人数不可预测，很容易弄挂站点。

- **创业小公司**
每年新增的创业公司很多，程序开发完后，缺少数据支撑，出于公司生死存亡的考虑，不断爬取数据。

<!-- more -->

- **不小心写错了没人去停止的失控小爬虫**
像知乎，携程，财经等网站，可能高达60%的访问量是爬虫。你就算直接封杀，也无济于事。他们可能根本爬不到任何数据了，除了http code是200以外，一切都是不对的，但由于托管后无人认领，仍然会依然孜孜不倦地爬取。

- **成型的商业对手**
这是最大的对手，有技术，有钱，要什么有什么，如果和你死磕，你就只能硬着头皮和他死磕。

- **抽风的搜索引擎**
搜索引擎也有抽风的时候，而且一抽风就会导致服务器性能下降，请求量跟网络攻击没有区别。

---

### 常见的爬虫、反爬虫、反反爬虫手段

爬虫 | 反爬虫 |
---|---
对某个网站或者APP的数据感兴趣。 <sup>**[1]**</sup>|
首先分析网站/APP  <sup>**[2]**</sup>的请求与返回数据，然后用python，或Java，或网上免费的抓取软件，不断遍历某列表抓取数据存数据库。|
|zabbix等监控显示某时间段请求陡增，ip相同，useragent还是JavaClient，直接Nginx封杀这个ip
useragent模仿谷歌或者百度浏览器，再获取十几个代理ip，爬的过程中不断轮询替换ip|
|发现ip不断变化，直接每次请求添加用户是否登录的校验
通过注册等各种方法，获取一个真实账号，模拟登录，每次请求携带登录产生的cookie或者token。|
|健全账号权限体系，即拥有A的账号，无法获取账号B的数据访问权限。
设置定时器，简单粗暴的直接爬取所有能爬取的数据|
|针对多IP的高频访问，Nginx设置频率限制，如某个ip短时间访问超过一定次数就直接屏蔽，一定程度增加爬虫方获取有效IP的成本
写代码爬取ip代理网站，或者批量购买高匿代理ip，几千IP轮询爬|
|在访问频率上继续做文章，升级ip限制策略，加大ip限制的成功率。 <sup>**[3]**</sup>
ip大量被封，为了解决这问题，开始模拟人类请求特征，比如每半小时爬取改为随机1-3秒爬一次，爬10次休息10秒，每天只在8-12，18-0点爬，隔几天还休息一下。再比如为了减少请求，能只抓列表页就不抓详情页|
|此刻再在访问频率上做限制，可能会误伤真实用户。如果网站类型不太注重用户体验，可以访问一定次数强制弹框要求输入验证码。 <sup>**[4]**</sup>
简单的验证码，完全可以自学图像识别的教程（关键词PIL，tesseract），对验证码进行二值化预处理，分割，模式训练后，识别验证码。<sup>**[5]**</sup>|
|针对具有用户行为的爬虫，首先要明白，爬虫与人类在访问特征上最大的不一样在于，人不会长时间持续访问一个网站，而爬虫的访问数量会随着时间增长而线性增长<sup>**[6]**</sup>。根据这特征，分析请求日志，设置ip黑名单。
由于各种限制，单个爬虫轮询ip模拟用户行为进行爬取，效率已经大大降低。这个时候有条件，可以考虑分布式，跨省跨机房，利用ADSL进行长期爬取。|
|既然无法避免被爬，那就继续加大对方爬取成本。<sup>**[7]**</sup>
如果死磕到底。。|
| 只能硬着头皮和他继续死磕，直到一方因为机器成本与人力成本问题放弃。

</br>

[1] 爬取的前提是知道网站/APP的存在，如果系统不对外开放，你可能连它的存在都不知道。

[2] APP的请求可以用Fiddler抓取，具体操作见文尾的相关链接。一些APP的爬取相对Web难度较高，文本可能进行了压缩和加密，甚至为了节省用户流量，部分请求不走后端，Fiddler自然抓取不到。

[3] 拦截率越高的策略，误伤率就越高，甚至影响搜索引擎的收录。如果网站包含不希望被搜索引擎收录的内容，可以在站点部署 [robots](http://baike.baidu.com/item/robots协议/2483797?fromtitle=robots.txt&fromid=9518761&type=search) 文件。

[4] 知乎就不太可能为了反扒强制要求输入验证码，而CSDN的文件一旦下载次数过多，就会强制输入验证码。

[5] 关于验证码的识别与反识别也是一部恢弘壮丽的斗争史，目前的人机识别验证就是比较有效的反爬手段。数字验证码识别详见: [爬虫的坎坷之路-数字验证码识别](http://www.toutiao.com/i6301877355489001986/)

[6] 关于人类访问特征的介绍，详见: [当爬虫不遵守 robots 协议时，有没有防止抓取的可能？](https://www.zhihu.com/question/22324380/answer/120093636)

[7] 反爬虫的关键在于阻止被批量爬取，重点在批量。反爬虫技术的核心在于不断变更规则，比如不断变更验证码。
我们在内容上可以做如下文章：
- 网站不同地方的文本内容添加不同的自带标签。
- 关键数据由文本转为图片形式，并自带水印等。
- 间接关闭网站关键数据的查看入口，核心内容像百度文库一样改为word、pdf或者ppt下载模式，高频下载需要验证码或者账号积分。
- 网站不提供注册入口，或者注册需要内部推荐或者评审，加大爬虫方获取账号的难度。
- 网站的请求url复杂化，比如弄的像淘宝一样没有规律，id改为UUID等。
- 前端页面尽可能不暴露唯一ID，增加对方爬取后的去重成本。比如题库网站有一道道的试题，如果暴露QuestionID，对方可以直接去重。
- 前端html页面别一次性加载列表，根据用户点击js动态加载。即查询页面源码时，只能看到列表的第一条数据。
- 当确定访问异常时，大量返回虚假数据。爬虫几乎没有判断数据真假的能力。
- 核心数据提高安全等级，单独加密等。
....

---

### 疑问相关
**1、爬虫是否涉嫌违法？ 如果是的话，怎么要求赔偿？**
爬取的内容商业使用目前更倾向属于违法行为，但是在国内还是个擦边球，难以起诉成功。如果不想被批量爬取，技术才是最后保障。

**2、在爬虫与反爬虫的对弈中，谁会胜利？**
爬虫与反爬虫的重点都在于批量，没有绝对的胜利方。但是可以确定的是，只要人类能够正常访问的网页，爬虫在具备同等资源的情况下一定是可以抓取到，只是能否短时间内大批量爬取的问题。

**3、怎么快速爬取数据？**
首先考虑的是用网上各种破解版爬虫软件爬取数据，比如火车头采集器。即能用软件解决的爬取步骤，就没必要写代码实现，因为程序员比软件和服务器等资源金贵。其次考虑的才应该是如何用代码解决软件实现不了的步骤。

**4、为什么需要反爬虫？**
 - 公司的重要资源被批量爬取，丧失竞争力。
 - 爬虫占总PV比例太高，因为高访问量浪费了太多钱。
 - 爬虫拖垮了站点，严重影响了用户体验。
 - 资源被爬取难以起诉成功，对方可以肆意爬取。

---

### 链接相关
- 有哪些网站用爬虫能爬到很有价值的数据？
https://www.zhihu.com/question/36132174
![](http://7xvfir.com1.z0.glb.clouddn.com/%E7%88%AC%E8%99%AB%E3%80%81%E5%8F%8D%E7%88%AC%E8%99%AB%E3%80%81%E5%8F%8D%E5%8F%8D%E7%88%AC%E8%99%AB/1.png)

- 利用爬虫技术能做到哪些很酷很有趣很有用的事情？
https://www.zhihu.com/question/27621722

![](http://7xvfir.com1.z0.glb.clouddn.com/%E7%88%AC%E8%99%AB%E3%80%81%E5%8F%8D%E7%88%AC%E8%99%AB%E3%80%81%E5%8F%8D%E5%8F%8D%E7%88%AC%E8%99%AB/2.png)

- 突破反爬虫的利器——开源IP代理池【附源码】
https://zhuanlan.zhihu.com/p/23928595

- 验证码对抗之路及现有验证机制介绍
https://yq.aliyun.com/articles/57807?spm=5176.100240.searchblog.21.OuIr47

- 12306 售票网站新版验证码识别对抗
https://segmentfault.com/a/1190000002606801

- heritrix3 Java爬虫框架
https://github.com/internetarchive/heritrix3

- 18款Java开源Web爬虫【Heritrix等】
https://www.oschina.net/news/77402/19-java-open-source-web-crawler

- fiddler对浏览器、app抓包及证书安装
http://blog.csdn.net/u011608531/article/details/50838227

- 火车头采集器帮助文档
http://www.locoy.com/index/guide