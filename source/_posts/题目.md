---
title: 题目
tags:
  - 机器学习
categories:
  - 知识总结
date: 2018-2-20 22:22:00
toc: false
mathjax: true

---

给你一个有1000列和1百万行的训练数据集，这个数据集是基于分类问题的。经理要求你来降低该数据集的维度以减少模型计算时间，但你的机器内存有限。你会怎么做？（你可以自由做各种实际操作假设。）

答：你的面试官应该非常了解很难在有限的内存上处理高维的数据。以下是你可以使用的处理方法：

1.首先尽可能腾空内存，关闭机器上正在运行的非必要程序，以确保大部分内存可以使用。

2.然后随机采样，创建一个较小的数据集。比如30万行1000列，然后做计算。

3.在30W的数据上进行降维，我们可以把数值变量和分类变量分开，同时删掉相关联的变量。对于数值变量，我们将使用相关性分析；对于分类变量，我们可以用卡方检验。

4.降维还可以使用PCA（主成分分析），并挑选可以解释在数据集中有最大偏差的成分。

5.我们也可以用我们对业务的理解来估计各预测变量对响应变量的影响的大小。但是，这是一个主观的方法，如果没有找出有用的预测变量可能会导致信息的显著丢失。

6.利用在线学习算法，如VowpalWabbit（在Python中可用）是一个不错的选择。VW是由前Yahoo! Research的John Langford开发的一个大规模机器学习工具. 其训练速度很快, 在20亿条训练样本, 每个训练样本大概100个非零特征的情况下, 如果特征的总维数为一万时, 训练时间为20分钟, 特征总位数为1000万时, 训练时间为2个小时

7.可以使用Mini-Batch或SGD建立线性模型，然后用队列读取数据等也有一定帮助

<!-- more -->

---

给你一个数据集，这个数据集有缺失值，且这些缺失值分布在离中值有1个标准偏差的范围内。百分之多少的数据不会受到影响？为什么？

答：约有32%的数据将不受缺失值的影响。因为，由于数据分布在中位数附近，让我们先假设这是一个正态分布。我们知道，在一个正态分布中，约有68%的数据位于跟平均数（或众数、中位数）1个标准差范围内，那么剩下的约32%的数据是不受影响的。因此，约有32%的数据将不受缺失值的影响。

68.268949%的面积在平均数左右的一个标准差范围内。
95.449974%的面积在平均数左右两个标准差的范围内。
99.730020%的面积在平均数左右三个标准差的范围内。
99.993666%的面积在平均数左右四个标准差的范围内。

---

协方差和相关性有什么区别？

答：**相关性是协方差的标准化格式**。协方差本身很难做比较。例如：如果我们计算工资（$）和年龄（岁）的协方差，因为这两个变量有不同的度量，所以我们会得到不能做比较的不同的协方差。为了解决这个问题，我们**计算相关性来得到一个介于-1和1之间的值**，就可以忽略它们各自不同的度量。


---

你认为把分类变量当成连续型变量会更得到一个更好的预测模型吗？

答：为了得到更好的预测，只有在分类变量在本质上是**有序的情况下**才可以被当做连续型变量来处理。

---

“买了这个的客户，也买了......”亚马逊的建议是哪种算法的结果？

答：这种推荐引擎的基本想法来自于**协同过滤**。协同过滤算法考虑用于推荐项目的“用户行为”。它们利用的是其他用户的购买行为和针对商品的交易历史记录、评分、选择和购买信息。**针对商品的其他用户的行为和偏好**用来推荐项目（商品）给新用户。**在这种情况下，项目（商品）的特征是未知的。**


---

在k-means或kNN，我们是用欧氏距离来计算最近的邻居之间的距离。为什么不用曼哈顿距离？

答：我们不用曼哈顿距离，因为它只计算水平或垂直距离，有维度的限制。另一方面，欧氏距离可用于任何空间的距离计算问题。因为，数据点可以存在于任何空间，欧氏距离是更可行的选择。

---

花了几个小时后，现在你急于建一个高精度的模型。结果，你建了5 个GBM（Gradient Boosted Models），想着boosting算法会展现“魔力”。不幸的是，没有一个模型比基准模型表现得更好。最后，你决定将这些模型结合到一起。尽管众所周知，结合模型通常精度高，但你就很不幸运。你到底错在哪里？

答：据我们所知，组合的学习模型是基于合并弱的学习模型来创造一个强大的学习模型的想法。**但是，只有当各模型之间没有相关性的时候组合起来后才比较强大**。由于我们已经试了5个GBM也没有提高精度，表明这些模型是相关的。具有相关性的模型的问题是，所有的模型提供相同的信息。例如：如果模型1把User1122归类为1，模型2和模型3很有可能会做同样的分类，即使它的实际值应该是0，因此，只有弱相关的模型结合起来才会表现更好。

---

Gradient boosting算法（GBM）和随机森林都是基于树的算法，它们有什么区别？

答：最根本的区别是，随机森林算法使用bagging技术做出预测；而GBM是采用boosting技术做预测的。在bagging技术中，数据集用随机采样的方法被划分成n个样本。然后，使用单一的学习算法，在所有样本上建模。接着利用投票或者求平均来组合所得到的预测。**bagging是平行进行的，而boosting是在第一轮的预测之后，算法将分类出错的预测加高权重，使得它们可以在后续一轮中得到校正。**这种给予分类出错的预测高权重的顺序过程持续进行，一直到达到停止标准为止。**随机森林通过减少方差（主要方式）提高模型的精度。生成树之间是不相关的，以把方差的减少最大化。在另一方面，GBM提高了精度，同时减少了模型的偏差和方差。**

---

你会在时间序列数据集上使用什么交叉验证技术？是用k倍或LOOCV？

答：都不是。对于时间序列问题，k倍可能会很麻烦，因为第4年或第5年的一些模式有可能跟第3年的不同，而对数据集的重复采样会将分离这些趋势，而我们最终可能只是需要对过去几年的进行验证，这就不能用这种方法了。相反，我们可以采用如下所示的5倍正向链接策略：

fold 1 : training [1], test [2]
fold 2 : training [1 2], test [3]
fold 3 : training [1 2 3], test [4]
fold 4 : training [1 2 3 4], test [5]
fold 5 : training [1 2 3 4 5], test [6]
1，2，3，4，5，6代表的是年份。

注：LOOCV即留一验证， 留一验证意指只使用原本样本中的一个样本来当做验证资料， 而剩余的则留下来当做训练资料。 这个步骤一直持续到每个样本都被当做一次验证资料。 事实上，这等同于和K-fold 交叉验证是一样的，不过K为原本样本个数。 


---

何为共线性, 跟过拟合有啥关联?
- 共线性：多变量线性回归中，变量之间由于存在高度相关关系而使回归估计不准确。
- 共线性会造成冗余，导致过拟合。
- 解决方法：排除变量的相关性／加入权重正则。

---

=============未处理===============

---

我知道校正R2或者F值是用来评估线性回归模型的。那用什么来评估逻辑回归模型？

1.由于逻辑回归是用来预测概率的，我们可以用AUC-ROC曲线以及混淆矩阵来确定其性能。

2.此外，在逻辑回归中类似于校正R2的指标是AIC。AIC是对模型系数数量惩罚模型的拟合度量。因此，我们更偏爱有最小AIC的模型。

3.空偏差指的是只有截距项的模型预测的响应。数值越低，模型越好。残余偏差表示由添加自变量的模型预测的响应。数值越低，模型越好。

**ROC还是不理解**

---

什么是Box-Cox转换？
Box-Cox转换是一种广泛的“权力转型”，它转换数据，使分布更加正常。
例如，当lambda参数为0时，它相当于对数转换。
它用于稳定方差（消除异方差）并使分布正常化。

---

什么是3种数据预处理技术来处理异常值？
1.Winsorize（cap 阈值）。
2.转换以减少偏态（使用Box-Cox或类似的）。
3.如果你确定它们是异常或测量错误，请删除异常值。

---

减少维度的3种方法是什么？

1.去除共线特征。
2.执行PCA，ICA或降低其他形式的算法维数。
3.结合特征与特征工程。

---

如何根据训练集大小选择分类器？
如果训练集小，高偏置/低方差模型（例如朴素贝叶斯）往往是因为他们不太可能被过度拟合有更好的表现。
如果训练集很大，低偏差/高方差模型（如Logistic回归）往往表现更好，因为它们可以反映更复杂的关系。