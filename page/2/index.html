<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="generator" content="Hexo 4.2.1"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>星空str</title><meta description="ai,机器学习,深度学习,算法,leetcode,java"><meta property="og:type" content="blog"><meta property="og:title" content="Wasim37"><meta property="og:url" content="https://wangxin123.com/"><meta property="og:site_name" content="Wasim37"><meta property="og:description" content="ai,机器学习,深度学习,算法,leetcode,java"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://hexo-blog-wasim.oss-cn-shenzhen.aliyuncs.com/blog_avatar_lufei.png"><meta property="article:author" content="Wasim37"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="https://hexo-blog-wasim.oss-cn-shenzhen.aliyuncs.com/blog_avatar_lufei.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://wangxin123.com/"},"headline":"Wasim37","image":["https://hexo-blog-wasim.oss-cn-shenzhen.aliyuncs.com/blog_avatar_lufei.png"],"author":{"@type":"Person","name":"Wasim37"},"description":"ai,机器学习,深度学习,算法,leetcode,java"}</script><link rel="alternative" href="/atom.xml" title="星空str" type="application/atom+xml"><link rel="icon" href="https://hexo-blog-wasim.oss-cn-shenzhen.aliyuncs.com/wu.png"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.0/css/all.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Ubuntu:400,600|Source+Code+Pro"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-dark.css"><link rel="stylesheet" href="//fonts.googleapis.com/css?family=Monda:300,300italic,400,400italic,700,700italic|Roboto Slab:300,300italic,400,400italic,700,700italic|Microsoft YaHei:300,300italic,400,400italic,700,700italic|PT Mono:300,300italic,400,400italic,700,700italic&amp;amp;subset=latin,latin-ext"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><script><!-- hexo-inject:begin --><!-- hexo-inject:end -->var _hmt = _hmt || [];
        (function() {
            var hm = document.createElement("script");
            hm.src = "//hm.baidu.com/hm.js?060269356a8ca9046e6a13dcba6f9559";
            var s = document.getElementsByTagName("script")[0];
            s.parentNode.insertBefore(hm, s);
        })();</script><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" defer></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><link rel="stylesheet" href="/css/style.css"><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="/js/globalUtils.js"></script><!-- hexo-inject:begin --><!-- hexo-inject:end --></head><body class="is-3-column has-navbar-fixed-top"><nav class="navbar navbar-main is-fixed-top"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="https://hexo-blog-wasim.oss-cn-shenzhen.aliyuncs.com/logo.svg" alt="星空str" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">首页</a><a class="navbar-item" href="/archives">归档</a><a class="navbar-item" href="/categories">分类</a><a class="navbar-item" href="/tags">标签</a><a class="navbar-item" href="/about">关于</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="GitHub" href="https://github.com/wasim37"><i class="fab fa-github"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><script type="text/javascript" src="/js/theme-setting.js"></script><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2018-06-19T14:22:00.000Z">2018-06-19</time><a class="commentCountImg" href="/2018/06/19/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/#comment-container"><span class="display-none-class">70eddb3e36ac32c2a53a776db342486f</span><img class="not-gallery-item" src="https://hexo-blog-wasim.oss-cn-shenzhen.aliyuncs.com/chat.svg"> <span class="commentCount" id="70eddb3e36ac32c2a53a776db342486f"> 0</span>    </a><span class="level-item"><i class="fas fa-folder-open has-text-grey"> </i><a class="link-muted" href="/categories/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/">知识总结</a></span><span class="level-item">21 分钟 读完 (大约 3207 个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2018/06/19/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/">激活函数</a></h1><div class="content"><h3 id="什么是激活函数，为什么要用非线性激活函数"><a href="#什么是激活函数，为什么要用非线性激活函数" class="headerlink" title="什么是激活函数，为什么要用非线性激活函数"></a>什么是激活函数，为什么要用非线性激活函数</h3><p>如下图，在神经元中，输入的 inputs 通过加权，求和后，还被作用了一个函数，这个函数就是激活函数 Activation Function。<br><img src="https://hexo-blog-wasim.oss-cn-shenzhen.aliyuncs.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E7%82%B9%E9%9B%86%E9%94%A6/61.png" alt=""></p>
<!-- hexo-inject:begin --><!-- hexo-inject:end --><p><strong>不用激活函数或使用线性激活函数，和直接使用 Logistic 回归没有区别</strong>，因为无论神经网络有多少层，输出都是输入的线性组合，与没有隐藏层效果相当，就成了最原始的感知器了。</p>
<p><strong>非线性激活函数给神经元引入了非线性因素，使得神经网络可以任意逼近任何非线性函数</strong>，这样神经网络就可以应用到众多的非线性模型中。非线性激励函数最早的想法是sigmoid函数或者tanh函数，输出有界，很容易充当下一层输入。</p></div><div class="level is-mobile is-flex"><div class="level-start"><div class="is-uppercase article-more button is-small size-small"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted mr-2" rel="tag" href="/tags/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/">激活函数</a></div></div><div class="level-start"><div class="level-item"><a class="article-more button is-small size-small link-muted" href="/2018/06/19/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/#more"><i class="fas fa-book-reader has-text-grey"> </i>阅读更多&gt;&gt;</a></div></div></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2018-06-17T14:22:00.000Z">2018-06-17</time><a class="commentCountImg" href="/2018/06/17/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/#comment-container"><span class="display-none-class">22ba2f198e13fbfd8be60c3bcdf5f1b9</span><img class="not-gallery-item" src="https://hexo-blog-wasim.oss-cn-shenzhen.aliyuncs.com/chat.svg"> <span class="commentCount" id="22ba2f198e13fbfd8be60c3bcdf5f1b9"> 0</span>    </a><span class="level-item"><i class="fas fa-folder-open has-text-grey"> </i><a class="link-muted" href="/categories/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/">特征工程</a></span><span class="level-item">39 分钟 读完 (大约 5911 个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2018/06/17/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/">特征工程</a></h1><div class="content"><h2 id="特征工程是什么"><a href="#特征工程是什么" class="headerlink" title="特征工程是什么"></a>特征工程是什么</h2><p><strong>数据和特征决定机器学习上限，而模型和算法只是逼近这个上限</strong>。<br><strong>特征工程目的：最大限度地从原始数据中提取特征以供算法和模型使用</strong>。</p>
<hr>
<h2 id="数据清洗"><a href="#数据清洗" class="headerlink" title="数据清洗"></a>数据清洗</h2><p>数据清洗的结果直接关系到模型效果以及最终的结论。在实际的工作中，数据清洗通常占开发过程的 50%-80% 的时间。</p>
<p>在数据预处理过程主要考虑两个方面，如下：</p>
<ul>
<li>选择数据处理工具：关系型数据库戒者Python</li>
<li>查看数据的元数据以及数据特征：一是查看元数据，包括字段解释、数据来源等一切可以描述数据的信息；另外是抽取一部分数据，通过人工查看的方式，对数据本身做一个比较直观的了解，并且初步发现一些问题，为之后的数据处理做准备。</li>
</ul>
<h3 id="缺省值清洗"><a href="#缺省值清洗" class="headerlink" title="缺省值清洗"></a>缺省值清洗</h3><p>缺省值是数据中最常见的一个问题，处理缺省值有很多方式，主要包括以下四个步骤进行缺省值处理：</p>
<ul>
<li>确定缺省值范围</li>
<li>去除不需要的字段</li>
<li>填充缺省值内容</li>
<li>重新获取数据</li>
</ul>
<p>注意：最重要的是 <strong>缺省值内容填充。</strong></p></div><div class="level is-mobile is-flex"><div class="level-start"><div class="is-uppercase article-more button is-small size-small"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted mr-2" rel="tag" href="/tags/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/">特征工程</a></div></div><div class="level-start"><div class="level-item"><a class="article-more button is-small size-small link-muted" href="/2018/06/17/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/#more"><i class="fas fa-book-reader has-text-grey"> </i>阅读更多&gt;&gt;</a></div></div></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2018-06-17T14:22:00.000Z">2018-06-17</time><a class="commentCountImg" href="/2018/06/17/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/%E6%A2%AF%E5%BA%A6%E6%B6%88%E5%A4%B1%E4%B8%8E%E6%A2%AF%E5%BA%A6%E7%88%86%E7%82%B8/#comment-container"><span class="display-none-class">22e290b7a81180c2ab3daf033f6ec675</span><img class="not-gallery-item" src="https://hexo-blog-wasim.oss-cn-shenzhen.aliyuncs.com/chat.svg"> <span class="commentCount" id="22e290b7a81180c2ab3daf033f6ec675"> 0</span>    </a><span class="level-item"><i class="fas fa-folder-open has-text-grey"> </i><a class="link-muted" href="/categories/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/">知识总结</a></span><span class="level-item">13 分钟 读完 (大约 1897 个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2018/06/17/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/%E6%A2%AF%E5%BA%A6%E6%B6%88%E5%A4%B1%E4%B8%8E%E6%A2%AF%E5%BA%A6%E7%88%86%E7%82%B8/">梯度消失与梯度爆炸</a></h1><div class="content"><h3 id="什么是梯度消失和梯度爆炸，分别会引发什么问题"><a href="#什么是梯度消失和梯度爆炸，分别会引发什么问题" class="headerlink" title="什么是梯度消失和梯度爆炸，分别会引发什么问题"></a>什么是梯度消失和梯度爆炸，分别会引发什么问题</h3><p>我们知道神经网络在训练过程中会利用梯度对网络的权重进行更新迭代。<br>当梯度出现指数级递减或指数递增时，称为梯度消失或者梯度爆炸。</p>
<p>假定激活函数 $g(z) = z$, 令 $b^{[l]} = 0$，对于目标输出有：<br>$\hat{y} = W^{[L]}W^{[L-1]}…W^{[2]}W^{[1]}X$<br>1）对于 W[l]的值小于 1 的情况，激活函数的值将以指数级递减<br>2）对于 W[l]的值大于 1 的情况，激活函数的值将以指数级递增<br>同理的情况会出现在反向求导。</p>
<p>梯度消失时，权重更新缓慢，训练难度大大增加。梯度消失相对梯度爆炸更常见。<br>梯度爆炸时，权重大幅更新，网络变得不稳定。较好的情况是网络无法利用训练数据学习，最差的情况是权值增大溢出，变成网络无法更新的 NaN 值。</p></div><div class="level is-mobile is-flex"><div class="level-start"><div class="is-uppercase article-more button is-small size-small"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted mr-2" rel="tag" href="/tags/%E6%A2%AF%E5%BA%A6%E6%B6%88%E5%A4%B1/">梯度消失</a><a class="link-muted mr-2" rel="tag" href="/tags/%E6%A2%AF%E5%BA%A6%E7%88%86%E7%82%B8/">梯度爆炸</a></div></div><div class="level-start"><div class="level-item"><a class="article-more button is-small size-small link-muted" href="/2018/06/17/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/%E6%A2%AF%E5%BA%A6%E6%B6%88%E5%A4%B1%E4%B8%8E%E6%A2%AF%E5%BA%A6%E7%88%86%E7%82%B8/#more"><i class="fas fa-book-reader has-text-grey"> </i>阅读更多&gt;&gt;</a></div></div></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2018-06-08T14:22:00.000Z">2018-06-08</time><a class="commentCountImg" href="/2018/06/08/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9/#comment-container"><span class="display-none-class">8552ceb9e311a7f667447db875004262</span><img class="not-gallery-item" src="https://hexo-blog-wasim.oss-cn-shenzhen.aliyuncs.com/chat.svg"> <span class="commentCount" id="8552ceb9e311a7f667447db875004262"> 0</span>    </a><span class="level-item"><i class="fas fa-folder-open has-text-grey"> </i><a class="link-muted" href="/categories/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/">特征工程</a></span><span class="level-item">10 分钟 读完 (大约 1561 个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2018/06/08/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9/">特征选择</a></h1><div class="content"><p>待整理，需要合并指”特征工程文档中”。。。</p>
<h1 id="机器学习中，有哪些特征选择的工程方法"><a href="#机器学习中，有哪些特征选择的工程方法" class="headerlink" title="机器学习中，有哪些特征选择的工程方法"></a>机器学习中，有哪些特征选择的工程方法</h1><p><strong>数据和特征决定了机器学习的上限，而模型和算法只是逼近这个上限而已</strong></p>
<ul>
<li><p><strong>计算每一个特征与响应变量的相关性</strong><br>工程上常用的手段有计算<strong>皮尔逊系数</strong>和<strong>互信息系数</strong>，<strong>皮尔逊系数只能衡量线性相关性</strong>，而**互信息系数能够很好地度量各种相关性，但是计算相对复杂一些，好在很多toolkit里边都包含了这个工具（如sklearn的MINE），得到相关性之后就可以排序选择特征了；</p>
</li>
<li><p><strong>构建单个特征的模型，通过模型的准确性为特征排序，借此来选择特征；</strong></p>
</li>
<li><p><strong>通过L1正则项来选择特征</strong><br>L1正则方法具有稀疏解的特性，因此天然具备特征选择的特性，但是要注意，L1没有选到的特征不代表不重要，原因是两个具有高相关性的特征可能只保留了一个，如果要确定哪个特征重要应再通过L2正则方法交叉检验；</p>
</li>
<li><p><strong>训练能够对特征打分的预选模型</strong><br>RandomForest和Logistic Regression等都能对模型的特征打分，通过打分获得相关性后再训练最终模型；</p>
</li>
<li><p><strong>通过特征组合后再来选择特征</strong><br>如对用户id和用户特征最组合来获得较大的特征集再来选择特征，这种做法在推荐系统和广告系统中比较常见，这也是所谓亿级甚至十亿级特征的主要来源，原因是用户数据比较稀疏，组合特征能够同时兼顾全局模型和个性化模型。</p>
</li>
<li><p><strong>通过深度学习来进行特征选择</strong><br>目前这种手段正在随着深度学习的流行而成为一种手段，尤其是在计算机视觉领域，原因是深度学习具有自动学习特征的能力，这也是深度学习又叫unsupervised feature learning的原因。从深度学习模型中选择某一神经层的特征后就可以用来进行最终目标模型的训练了。</p>
</li>
</ul></div><div class="level is-mobile is-flex"><div class="level-start"><div class="is-uppercase article-more button is-small size-small"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted mr-2" rel="tag" href="/tags/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/">特征工程</a></div></div><div class="level-start"><div class="level-item"><a class="article-more button is-small size-small link-muted" href="/2018/06/08/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9/#more"><i class="fas fa-book-reader has-text-grey"> </i>阅读更多&gt;&gt;</a></div></div></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2018-06-02T14:22:00.000Z">2018-06-02</time><a class="commentCountImg" href="/2018/06/02/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/#comment-container"><span class="display-none-class">441572d694a28adc232a1d6d8c45da2e</span><img class="not-gallery-item" src="https://hexo-blog-wasim.oss-cn-shenzhen.aliyuncs.com/chat.svg"> <span class="commentCount" id="441572d694a28adc232a1d6d8c45da2e"> 0</span>    </a><span class="level-item"><i class="fas fa-folder-open has-text-grey"> </i><a class="link-muted" href="/categories/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/">知识总结</a></span><span class="level-item">42 分钟 读完 (大约 6274 个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2018/06/02/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">机器学习笔记</a></h1><div class="content"><ul>
<li><a href="http://www.ai-start.com/ml2014/html/week8.html#header-n186">PCA_吴恩达</a></li>
<li><a href="http://www.ai-start.com/ml2014/html/week9.html#header-n5">异常值检测_吴恩达</a></li>
<li><a href="http://www.ai-start.com/ml2014/html/week9.html#header-n279">推荐系统_吴恩达</a></li>
<li><a href="https://www.zhihu.com/question/19971859">协同过滤和基于内容推荐有什么区别</a></li>
</ul>
<ul>
<li><a href="https://www.zhihu.com/question/23259302">如何准备机器学习工程师的面试</a></li>
<li><a href="https://www.zhihu.com/question/62482926">如何判断某个人的机器学习水平</a></li>
</ul>
<hr></div><div class="level is-mobile is-flex"><div class="level-start"><div class="is-uppercase article-more button is-small size-small"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted mr-2" rel="tag" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></div></div><div class="level-start"><div class="level-item"><a class="article-more button is-small size-small link-muted" href="/2018/06/02/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/#more"><i class="fas fa-book-reader has-text-grey"> </i>阅读更多&gt;&gt;</a></div></div></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2018-05-19T14:22:00.000Z">2018-05-19</time><a class="commentCountImg" href="/2018/05/19/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/%E5%8D%B7%E7%A7%AF%E5%B1%82%E3%80%81%E6%B1%A0%E5%8C%96%E5%B1%82%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5%E5%B1%82%E8%AF%A6%E8%A7%A3/#comment-container"><span class="display-none-class">86109051b0142bf1e47e565e0ab24901</span><img class="not-gallery-item" src="https://hexo-blog-wasim.oss-cn-shenzhen.aliyuncs.com/chat.svg"> <span class="commentCount" id="86109051b0142bf1e47e565e0ab24901"> 0</span>    </a><span class="level-item"><i class="fas fa-folder-open has-text-grey"> </i><a class="link-muted" href="/categories/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/">知识总结</a></span><span class="level-item">26 分钟 读完 (大约 3896 个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2018/05/19/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/%E5%8D%B7%E7%A7%AF%E5%B1%82%E3%80%81%E6%B1%A0%E5%8C%96%E5%B1%82%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5%E5%B1%82%E8%AF%A6%E8%A7%A3/">卷积层、池化层和全连接层详解</a></h1><div class="content"><h3 id="为什么使用卷积"><a href="#为什么使用卷积" class="headerlink" title="为什么使用卷积"></a>为什么使用卷积</h3><p>相比标准神经网络，对于大量的输入数据，卷积过程有效地减少了 CNN 的参数数量，原因有以下两点：</p>
<ul>
<li><p><strong>参数共享（Parameter sharing）</strong>：特征检测如果适用于图片的某个区域，那么它也可能适用于图片的其他区域。即在卷积过程中，不管输入有多大，一个特征探测器（滤波器）就能对整个输入的某一特征进行探测。</p>
</li>
<li><p><strong>稀疏连接（Sparsity of connections）</strong>：在每一层中，由于滤波器的尺寸限制，输入和输出之间的连接是稀疏的，每个输出值只取决于输入在局部的一小部分值。<br>池化过程则在卷积后很好地聚合了特征，通过降维来减少运算量。</p>
</li>
</ul>
<p>由于 CNN 参数数量较小，所需的训练样本就相对较少，因此在一定程度上不容易发生过拟合现象。并且 CNN 比较擅长捕捉区域位置偏移。即进行物体检测时，不太受物体在图片中位置的影响，增加检测的准确性和系统的健壮性。</p>
<p>然后这篇<a href="https://zhuanlan.zhihu.com/p/23185164">文章</a>， 从感受视野的角度出发，解释了参数共享、稀疏连接、平移不变性等</p>
<p><strong>然后卷积层可以看做全连接的一种简化形式:不全连接+不参数共享。所以全连接层的参数才如此之多。</strong></p></div><div class="level is-mobile is-flex"><div class="level-start"><div class="is-uppercase article-more button is-small size-small"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted mr-2" rel="tag" href="/tags/%E5%8D%B7%E7%A7%AF%E5%B1%82/">卷积层</a><a class="link-muted mr-2" rel="tag" href="/tags/%E6%B1%A0%E5%8C%96%E5%B1%82/">池化层</a><a class="link-muted mr-2" rel="tag" href="/tags/%E5%85%A8%E8%BF%9E%E6%8E%A5%E5%B1%82/">全连接层</a></div></div><div class="level-start"><div class="level-item"><a class="article-more button is-small size-small link-muted" href="/2018/05/19/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/%E5%8D%B7%E7%A7%AF%E5%B1%82%E3%80%81%E6%B1%A0%E5%8C%96%E5%B1%82%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5%E5%B1%82%E8%AF%A6%E8%A7%A3/#more"><i class="fas fa-book-reader has-text-grey"> </i>阅读更多&gt;&gt;</a></div></div></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2018-05-03T14:22:00.000Z">2018-05-03</time><a class="commentCountImg" href="/2018/05/03/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/%E8%BF%87%E6%8B%9F%E5%90%88%E4%B8%8E%E6%AC%A0%E6%8B%9F%E5%90%88/#comment-container"><span class="display-none-class">7713531352a0d3c06818b77e70250816</span><img class="not-gallery-item" src="https://hexo-blog-wasim.oss-cn-shenzhen.aliyuncs.com/chat.svg"> <span class="commentCount" id="7713531352a0d3c06818b77e70250816"> 0</span>    </a><span class="level-item"><i class="fas fa-folder-open has-text-grey"> </i><a class="link-muted" href="/categories/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/">知识总结</a></span><span class="level-item">11 分钟 读完 (大约 1649 个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2018/05/03/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/%E8%BF%87%E6%8B%9F%E5%90%88%E4%B8%8E%E6%AC%A0%E6%8B%9F%E5%90%88/">过拟合与欠拟合</a></h1><div class="content"><h1 id="什么是过拟合和欠拟合"><a href="#什么是过拟合和欠拟合" class="headerlink" title="什么是过拟合和欠拟合"></a>什么是过拟合和欠拟合</h1><p><strong>欠拟合</strong>：算法不太符合样本的数据特征<br><strong>过拟合</strong>：算法太符合样本的数据特征，对实际生产中的数据特征却无法拟合</p>
<p>过拟合(overfitting)具体现象体现为，随着训练过程的进行，模型复杂度增加，在训练集上的错误率渐渐减小，但是在验证集上的错误率却渐渐增大。</p>
<p>特征过多，特征数量级过大，训练数据过少，都可能导致过度拟合。过拟合会让模型泛化能力变差。</p>
<p><img src="https://hexo-blog-wasim.oss-cn-shenzhen.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E7%82%B9%E9%9B%86%E9%94%A6/4.png" alt=""></p></div><div class="level is-mobile is-flex"><div class="level-start"><div class="is-uppercase article-more button is-small size-small"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted mr-2" rel="tag" href="/tags/%E8%BF%87%E6%8B%9F%E5%90%88/">过拟合</a><a class="link-muted mr-2" rel="tag" href="/tags/%E6%AC%A0%E6%8B%9F%E5%90%88/">欠拟合</a></div></div><div class="level-start"><div class="level-item"><a class="article-more button is-small size-small link-muted" href="/2018/05/03/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/%E8%BF%87%E6%8B%9F%E5%90%88%E4%B8%8E%E6%AC%A0%E6%8B%9F%E5%90%88/#more"><i class="fas fa-book-reader has-text-grey"> </i>阅读更多&gt;&gt;</a></div></div></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2018-05-02T14:22:00.000Z">2018-05-02</time><a class="commentCountImg" href="/2018/05/02/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/%E5%BD%92%E4%B8%80%E5%8C%96/#comment-container"><span class="display-none-class">6b099def6872416f6d3fb8135e157830</span><img class="not-gallery-item" src="https://hexo-blog-wasim.oss-cn-shenzhen.aliyuncs.com/chat.svg"> <span class="commentCount" id="6b099def6872416f6d3fb8135e157830"> 0</span>    </a><span class="level-item"><i class="fas fa-folder-open has-text-grey"> </i><a class="link-muted" href="/categories/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/">知识总结</a></span><span class="level-item">10 分钟 读完 (大约 1472 个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2018/05/02/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/%E5%BD%92%E4%B8%80%E5%8C%96/">归一化</a></h1><div class="content"><h2 id="一、数值类型特征常用归一化方法"><a href="#一、数值类型特征常用归一化方法" class="headerlink" title="一、数值类型特征常用归一化方法"></a>一、数值类型特征常用归一化方法</h2><h3 id="1、线性函数归一化（Min-Max-Scaling）"><a href="#1、线性函数归一化（Min-Max-Scaling）" class="headerlink" title="1、线性函数归一化（Min-Max Scaling）"></a>1、线性函数归一化（Min-Max Scaling）</h3><p>它对原始数据进行线性变换，使结果映射到[0, 1]的范围，实现对原始数据的等比缩放。<br>归一化公式如下，其中X为原始数据，X max 、X min 分别为数据最大值和最小值。<br><img src="https://hexo-blog-wasim.oss-cn-shenzhen.aliyuncs.com/20200527143850.png" alt=""></p>
<p><strong>优点</strong>：通过利用变量取值的最大值和最小值将原始数据转换为界于某一特定范围的数据，从 而消除量纲和数量级的影响<br><strong>缺点</strong>：由于极值化方法在对变量无量纲化过程中仅仅与该变量的最大值和最小值这两个极端 值有关，而与其他取值无关，这使得该方法在改变各变量权重时过分依赖两个极端取值。<strong>实际使用中可以用经验常量值来替代max和min。</strong></p>
<h3 id="2、零均值归一化（Z-Score-Normalization）"><a href="#2、零均值归一化（Z-Score-Normalization）" class="headerlink" title="2、零均值归一化（Z-Score Normalization）"></a>2、零均值归一化（Z-Score Normalization）</h3><p>它会将原始数据映射到均值为0、标准差为1的分布上。具体来说，假设原始特征的均值为μ、标准差为σ，那么<br>归一化公式定义为<br><img src="https://hexo-blog-wasim.oss-cn-shenzhen.aliyuncs.com/20200527144058.png" alt=""></p>
<p><strong>优点</strong>：去量纲化。我的理解就是通过某种方法能去掉实际过程中的单位，从而简化计算。<br><strong>缺点</strong>：这种归一化方式要求原始数据的分布可以近似为高斯分布，否则归一化的效果会变得很糟糕。</p></div><div class="level is-mobile is-flex"><div class="level-start"><div class="level-item"><a class="article-more button is-small size-small link-muted" href="/2018/05/02/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/%E5%BD%92%E4%B8%80%E5%8C%96/#more"><i class="fas fa-book-reader has-text-grey"> </i>阅读更多&gt;&gt;</a></div></div></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2018-04-18T14:22:00.000Z">2018-04-18</time><a class="commentCountImg" href="/2018/04/18/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%BC%80%E5%8F%91%E7%AD%96%E7%95%A5/#comment-container"><span class="display-none-class">26981a17655c35f151e2fc009c756884</span><img class="not-gallery-item" src="https://hexo-blog-wasim.oss-cn-shenzhen.aliyuncs.com/chat.svg"> <span class="commentCount" id="26981a17655c35f151e2fc009c756884"> 0</span>    </a><span class="level-item"><i class="fas fa-folder-open has-text-grey"> </i><a class="link-muted" href="/categories/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/">知识总结</a></span><span class="level-item">29 分钟 读完 (大约 4409 个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2018/04/18/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%BC%80%E5%8F%91%E7%AD%96%E7%95%A5/">机器学习开发策略</a></h1><div class="content"><h3 id="ML策略"><a href="#ML策略" class="headerlink" title="ML策略"></a>ML策略</h3><p>假设你构建了一个喵咪分类器，训练之后准确率达到90%，但在测试集上还不够好。此时你可以想到的优化方法有哪些呢？总结后大致如下：</p>
<ul>
<li>收集更多的数据</li>
<li>收集更多的多样化训练集，比如不同姿势的猫咪图片等</li>
<li>用梯度下降法训练更长时间</li>
<li>尝试Adam算法</li>
<li>尝试更大的网路</li>
<li>尝试小一点的网络</li>
<li>尝试dropout随机失活算法</li>
<li>加上L2正则项</li>
<li>改善网络结构，如变更激活函数，变更隐藏层节点数量</li>
</ul>
<p>优化的方法虽然很多，但如果方向错误，可能白费几个月时间。<br><strong>那通过哪些策略可以减少错误发生的几率呢？怎么判断哪些方法可以尝试，哪些方法可以丢弃呢？</strong></p></div><div class="level is-mobile is-flex"><div class="level-start"><div class="level-item"><a class="article-more button is-small size-small link-muted" href="/2018/04/18/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%BC%80%E5%8F%91%E7%AD%96%E7%95%A5/#more"><i class="fas fa-book-reader has-text-grey"> </i>阅读更多&gt;&gt;</a></div></div></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2018-04-10T14:22:00.000Z">2018-04-10</time><a class="commentCountImg" href="/2018/04/10/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E5%92%8C%E6%88%90%E6%9C%AC%E5%87%BD%E6%95%B0/#comment-container"><span class="display-none-class">07f70193549f2c282f081153ba34b0db</span><img class="not-gallery-item" src="https://hexo-blog-wasim.oss-cn-shenzhen.aliyuncs.com/chat.svg"> <span class="commentCount" id="07f70193549f2c282f081153ba34b0db"> 0</span>    </a><span class="level-item"><i class="fas fa-folder-open has-text-grey"> </i><a class="link-muted" href="/categories/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/">知识总结</a></span><span class="level-item">8 分钟 读完 (大约 1167 个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2018/04/10/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E5%92%8C%E6%88%90%E6%9C%AC%E5%87%BD%E6%95%B0/">损失函数和成本函数</a></h1><div class="content"><p><strong>损失函数针对的是单个样本，代价函数或者成本函数针对的是全体样本。</strong></p>
<hr>
<h3 id="逻辑回归"><a href="#逻辑回归" class="headerlink" title="逻辑回归"></a>逻辑回归</h3><p>Logistic 回归是一个用于二分分类的算法。</p>
<p>Logistic 回归中使用的参数如下：</p>
<ul>
<li>输入的特征向量：$x \in R^{n_x}$，其中 ${n_x}$ 是特征数量；</li>
<li>用于训练的标签：$y \in 0,1$</li>
<li>权重：$w \in R^{n_x}$</li>
<li>偏置： $b \in R$</li>
<li>输出：$\hat{y} = \sigma(w^Tx+b)$</li>
<li><strong>Sigmoid 函数</strong>：<script type="math/tex; mode=display">s = \sigma(w^Tx+b) = \sigma(z) = \frac{1}{1+e^{-z}}</script></li>
</ul></div><div class="level is-mobile is-flex"><div class="level-start"><div class="level-item"><a class="article-more button is-small size-small link-muted" href="/2018/04/10/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E5%92%8C%E6%88%90%E6%9C%AC%E5%87%BD%E6%95%B0/#more"><i class="fas fa-book-reader has-text-grey"> </i>阅读更多&gt;&gt;</a></div></div></div></article></div><nav class="pagination is-centered mt-4" role="navigation" aria-label="pagination"><div class="pagination-previous"><a href="/">上一页</a></div><div class="pagination-next"><a href="/page/3/">下一页</a></div><ul class="pagination-list is-hidden-mobile"><li><a class="pagination-link" href="/">1</a></li><li><a class="pagination-link is-current" href="/page/2/">2</a></li><li><a class="pagination-link" href="/page/3/">3</a></li><li><a class="pagination-link" href="/page/4/">4</a></li></ul></nav></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1 is-sticky"><!--!--><div class="card widget"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="is-rounded" src="https://hexo-blog-wasim.oss-cn-shenzhen.aliyuncs.com/blog_avatar_lufei.png" alt="星空str"></figure><p class="title is-size-4 is-block line-height-inherit">星空str</p><p class="is-size-6 is-block">Developer</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>GuangZhou, China</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="/archives"><p class="title">37</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分类</p><a href="/categories"><p class="title">9</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">标签</p><a href="/tags"><p class="title">34</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/wasim37" target="_blank" rel="noopener">关注我</a></div><div class="level is-mobile"><a class="level-item button is-transparent is-white is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/wasim37"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-white is-marginless" target="_blank" rel="noopener" title="Weibo" href="/"><i class="fab fa-weibo"></i></a><a class="level-item button is-transparent is-white is-marginless" target="_blank" rel="noopener" title="Email" href="/"><i class="fa fa-envelope"></i></a><a class="level-item button is-transparent is-white is-marginless" target="_blank" rel="noopener" title="Next" href="/"><i class="fab fa-dribbble"></i></a><a class="level-item button is-transparent is-white is-marginless" target="_blank" rel="noopener" title="RSS" href="/atom.xml"><i class="fas fa-rss"></i></a></div><hr></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">分类</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/categories/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/"><span class="level-start"><span class="level-item">特征工程</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/%E7%90%86%E8%AE%BA%E5%9F%BA%E7%A1%80/"><span class="level-start"><span class="level-item">理论基础</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/"><span class="level-start"><span class="level-item">知识总结</span></span><span class="level-end"><span class="level-item tag">12</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"><span class="level-start"><span class="level-item">神经网络</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/%E7%BB%8F%E5%85%B8%E6%A8%A1%E5%9E%8B/"><span class="level-start"><span class="level-item">经典模型</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/"><span class="level-start"><span class="level-item">自然语言处理</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"><span class="level-start"><span class="level-item">计算机视觉</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"><span class="level-start"><span class="level-item">论文阅读</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E8%B7%B5/"><span class="level-start"><span class="level-item">项目实践</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></div></div></div><div class="column-right-shadow is-hidden-widescreen"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3"><div class="card widget"><div class="card-content"><h3 class="menu-label">最新评论</h3><span class="body_hot_comment">加载中，最新评论有1分钟延迟...</span></div></div><div class="card widget"><div class="card-content"><h3 class="menu-label">最新文章</h3><article class="media"><div class="media-content size-small"><p><time dateTime="2019-05-21T14:22:00.000Z">2019-05-21</time></p><p class="title is-6"><a class="link-muted" href="/2019/05/21/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/%E7%9F%A5%E8%AF%86%E8%BF%BD%E8%B8%AA%E6%A8%A1%E5%9E%8B%E8%B0%83%E7%A0%94/">知识追踪模型调研</a></p><p class="is-uppercase"><i class="fas fa-folder-open has-text-grey"> </i><a class="link-muted" href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/">论文阅读</a></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2019-05-01T14:22:00.000Z">2019-05-01</time></p><p class="title is-6"><a class="link-muted" href="/2019/05/01/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E8%B7%B5/%E8%AF%95%E9%A2%98%E7%9F%A5%E8%AF%86%E7%82%B9%E6%99%BA%E8%83%BD%E6%A0%87%E6%B3%A8/">试题知识点智能标注</a></p><p class="is-uppercase"><i class="fas fa-folder-open has-text-grey"> </i><a class="link-muted" href="/categories/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E8%B7%B5/">项目实践</a></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2019-04-10T16:00:00.000Z">2019-04-11</time></p><p class="title is-6"><a class="link-muted" href="/2019/04/11/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/%E4%BB%8ENB%E5%88%B0%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/">从NB到语言模型</a></p><p class="is-uppercase"><i class="fas fa-folder-open has-text-grey"> </i><a class="link-muted" href="/categories/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/">自然语言处理</a></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2019-04-05T16:00:00.000Z">2019-04-06</time></p><p class="title is-6"><a class="link-muted" href="/2019/04/06/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%B8%8E%E5%9E%83%E5%9C%BE%E9%82%AE%E4%BB%B6/">贝叶斯与垃圾邮件</a></p><p class="is-uppercase"><i class="fas fa-folder-open has-text-grey"> </i><a class="link-muted" href="/categories/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/">自然语言处理</a></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2019-04-03T14:22:00.000Z">2019-04-03</time></p><p class="title is-6"><a class="link-muted" href="/2019/04/03/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E4%B8%8E%E8%AF%8D%E5%B5%8C%E5%85%A5/">自然语言处理与词嵌入</a></p><p class="is-uppercase"><i class="fas fa-folder-open has-text-grey"> </i><a class="link-muted" href="/categories/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/">自然语言处理</a></p></div></article></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">归档</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/archives/2019/05/"><span class="level-start"><span class="level-item">五月 2019</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2019/04/"><span class="level-start"><span class="level-item">四月 2019</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2018/09/"><span class="level-start"><span class="level-item">九月 2018</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2018/07/"><span class="level-start"><span class="level-item">七月 2018</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2018/06/"><span class="level-start"><span class="level-item">六月 2018</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><a class="level is-mobile is-marginless" href="/archives/"><span class="level-start"><span class="level-item">查看全部&gt;&gt;</span></span></a></ul></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">标签</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"><span class="tag">机器学习</span><span class="tag is-grey-lightest">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%B4%9D%E5%8F%B6%E6%96%AF/"><span class="tag">贝叶斯</span><span class="tag is-grey-lightest">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/RNN/"><span class="tag">RNN</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CNN/"><span class="tag">CNN</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/"><span class="tag">特征工程</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%A2%AF%E5%BA%A6%E6%B6%88%E5%A4%B1/"><span class="tag">梯度消失</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/StyleTransfer/"><span class="tag">StyleTransfer</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/YOLO/"><span class="tag">YOLO</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/word2vec/"><span class="tag">word2vec</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/"><span class="tag">人脸识别</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%85%A8%E8%BF%9E%E6%8E%A5%E5%B1%82/"><span class="tag">全连接层</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%86%B3%E7%AD%96%E6%A0%91/"><span class="tag">决策树</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%8D%B7%E7%A7%AF/"><span class="tag">卷积</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%8D%B7%E7%A7%AF%E5%B1%82/"><span class="tag">卷积层</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB/"><span class="tag">命名实体识别</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%8F%90%E5%8D%87%E7%AE%97%E6%B3%95/"><span class="tag">提升算法</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/KNN/"><span class="tag">KNN</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/NER/"><span class="tag">NER</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%A2%AF%E5%BA%A6%E7%88%86%E7%82%B8/"><span class="tag">梯度爆炸</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%AC%A0%E6%8B%9F%E5%90%88/"><span class="tag">欠拟合</span><span class="tag is-grey-lightest">1</span></a></div></div><div class="field is-grouped is-grouped-multiline"><a class="tags has-addons" href="/tags/"><span class="tag">查看全部&gt;&gt;</span></a></div></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="https://hexo-blog-wasim.oss-cn-shenzhen.aliyuncs.com/logo.svg" alt="星空str" height="28"></a><p class="size-small"><span>&copy; 2020 wasim37</span>  Powered by <a href="https://hexo.io/" target="_blank">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/wasim37"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script>moment.locale("zh-CN");</script><script>var IcarusThemeSettings = {
            site: {
                url: 'http://wangxin123.com',
                external_link: {"enable":true,"exclude":[]}
            },
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back-to-top.js" defer></script><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script src="/js/gallery.js" defer></script><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" defer></script><script>document.addEventListener("DOMContentLoaded", function() {
            document.querySelectorAll('[role="article"] > .content').forEach(function(element) {
                renderMathInElement(element);
            });
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            MathJax.Hub.Config({
                'HTML-CSS': {
                    matchFontHeight: false
                },
                SVG: {
                    matchFontHeight: false
                },
                CommonHTML: {
                    matchFontHeight: false
                },
                tex2jax: {
                    inlineMath: [
                        ['$','$'],
                        ['\\(','\\)']
                    ]
                }
            });
        });</script><!--!--><script src="/js/main.js" defer></script><script src="/js/comment-issue-data.js" defer></script><link rel="stylesheet" href="/css/insight.css"><div class="searchbox ins-search"><div class="searchbox-container ins-search-container"><div class="searchbox-input-wrapper"><input class="searchbox-input ins-search-input" type="text" placeholder="想要查找什么..."><span class="searchbox-close ins-close ins-selectable"><i class="fa fa-times-circle"></i></span></div><div class="searchbox-result-wrapper ins-section-wrapper"><div class="ins-section-container"></div></div></div></div><script>(function (window) {
            var INSIGHT_CONFIG = {
                TRANSLATION: {
                    POSTS: '文章',
                    PAGES: '页面',
                    CATEGORIES: '分类',
                    TAGS: '标签',
                    UNTITLED: '(无标题)',
                },
                CONTENT_URL: '/content.json',
            };
            window.INSIGHT_CONFIG = INSIGHT_CONFIG;
        })(window);</script><script src="/js/insight.js" defer></script><!-- hexo-inject:begin --><!-- hexo-inject:end --></body></html>