<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="generator" content="Hexo 4.2.1"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>循环训练模型 - wasim&#039;s blog</title><meta description="前言自然语言和音频都是前后相互关联的数据，对于这些序列数据需要使用循环神经网络（Recurrent Neural Network，RNN）来进行处理。 使用 RNN 实现的应用包括下图中所示："><meta property="og:type" content="blog"><meta property="og:title" content="循环训练模型"><meta property="og:url" content="http://www.wangxin123.com/2018/02/27/%E5%BE%AA%E7%8E%AF%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/"><meta property="og:site_name" content="wasim&#039;s blog"><meta property="og:description" content="前言自然语言和音频都是前后相互关联的数据，对于这些序列数据需要使用循环神经网络（Recurrent Neural Network，RNN）来进行处理。 使用 RNN 实现的应用包括下图中所示："><meta property="og:locale" content="zh_CN"><meta property="og:image" content="http://7xvfir.com1.z0.glb.clouddn.com/%E5%BE%AA%E7%8E%AF%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/20180424212312_Examples-of-Sequence-Model.png"><meta property="og:image" content="http://7xvfir.com1.z0.glb.clouddn.com/%E5%BE%AA%E7%8E%AF%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/Recurrent-Neural-Network.png"><meta property="og:image" content="http://7xvfir.com1.z0.glb.clouddn.com/%E5%BE%AA%E7%8E%AF%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/20180424211053_1.png"><meta property="og:image" content="http://7xvfir.com1.z0.glb.clouddn.com/%E5%BE%AA%E7%8E%AF%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/20180424211053_2.png"><meta property="og:image" content="http://7xvfir.com1.z0.glb.clouddn.com/%E5%BE%AA%E7%8E%AF%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/20180425095414.png"><meta property="og:image" content="http://7xvfir.com1.z0.glb.clouddn.com/%E5%BE%AA%E7%8E%AF%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/formula-of-RNN.png"><meta property="og:image" content="http://7xvfir.com1.z0.glb.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%89%8D%E5%90%91%E4%BC%A0%E6%92%AD.png"><meta property="og:image" content="http://7xvfir.com1.z0.glb.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD.png"><meta property="og:image" content="http://7xvfir.com1.z0.glb.clouddn.com/%E5%BE%AA%E7%8E%AF%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/Examples-of-RNN-architectures.png"><meta property="og:image" content="http://7xvfir.com1.z0.glb.clouddn.com/%E5%BE%AA%E7%8E%AF%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/language-model-RNN-example.png"><meta property="og:image" content="http://7xvfir.com1.z0.glb.clouddn.com/%E5%BE%AA%E7%8E%AF%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/Sampling-a-sequence-from-a-trained-RNN.png"><meta property="og:image" content="http://7xvfir.com1.z0.glb.clouddn.com/%E5%BE%AA%E7%8E%AF%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/20180424211053_3.png"><meta property="og:image" content="http://7xvfir.com1.z0.glb.clouddn.com/%E5%BE%AA%E7%8E%AF%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/20180424211053_4.png"><meta property="og:image" content="http://7xvfir.com1.z0.glb.clouddn.com/%E5%BE%AA%E7%8E%AF%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/20180424211053_5.png"><meta property="og:image" content="http://7xvfir.com1.z0.glb.clouddn.com/%E5%BE%AA%E7%8E%AF%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/LSTM.png"><meta property="og:image" content="http://7xvfir.com1.z0.glb.clouddn.com/%E5%BE%AA%E7%8E%AF%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/BRNN.png"><meta property="og:image" content="http://7xvfir.com1.z0.glb.clouddn.com/%E5%BE%AA%E7%8E%AF%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/DRNN.png"><meta property="article:published_time" content="2018-02-27T14:22:00.000Z"><meta property="article:modified_time" content="2020-05-19T06:34:18.437Z"><meta property="article:author" content="Wasim"><meta property="article:tag" content="RNN"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="http://7xvfir.com1.z0.glb.clouddn.com/%E5%BE%AA%E7%8E%AF%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/20180424212312_Examples-of-Sequence-Model.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://www.wangxin123.com/2018/02/27/%E5%BE%AA%E7%8E%AF%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/"},"headline":"wasim's blog","image":["http://7xvfir.com1.z0.glb.clouddn.com/%E5%BE%AA%E7%8E%AF%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/20180424212312_Examples-of-Sequence-Model.png","http://7xvfir.com1.z0.glb.clouddn.com/%E5%BE%AA%E7%8E%AF%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/Recurrent-Neural-Network.png","http://7xvfir.com1.z0.glb.clouddn.com/%E5%BE%AA%E7%8E%AF%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/20180424211053_1.png","http://7xvfir.com1.z0.glb.clouddn.com/%E5%BE%AA%E7%8E%AF%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/20180424211053_2.png","http://7xvfir.com1.z0.glb.clouddn.com/%E5%BE%AA%E7%8E%AF%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/20180425095414.png","http://7xvfir.com1.z0.glb.clouddn.com/%E5%BE%AA%E7%8E%AF%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/formula-of-RNN.png","http://7xvfir.com1.z0.glb.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%89%8D%E5%90%91%E4%BC%A0%E6%92%AD.png","http://7xvfir.com1.z0.glb.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD.png","http://7xvfir.com1.z0.glb.clouddn.com/%E5%BE%AA%E7%8E%AF%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/Examples-of-RNN-architectures.png","http://7xvfir.com1.z0.glb.clouddn.com/%E5%BE%AA%E7%8E%AF%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/language-model-RNN-example.png","http://7xvfir.com1.z0.glb.clouddn.com/%E5%BE%AA%E7%8E%AF%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/Sampling-a-sequence-from-a-trained-RNN.png","http://7xvfir.com1.z0.glb.clouddn.com/%E5%BE%AA%E7%8E%AF%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/20180424211053_3.png","http://7xvfir.com1.z0.glb.clouddn.com/%E5%BE%AA%E7%8E%AF%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/20180424211053_4.png","http://7xvfir.com1.z0.glb.clouddn.com/%E5%BE%AA%E7%8E%AF%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/20180424211053_5.png","http://7xvfir.com1.z0.glb.clouddn.com/%E5%BE%AA%E7%8E%AF%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/LSTM.png","http://7xvfir.com1.z0.glb.clouddn.com/%E5%BE%AA%E7%8E%AF%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/BRNN.png","http://7xvfir.com1.z0.glb.clouddn.com/%E5%BE%AA%E7%8E%AF%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/DRNN.png"],"datePublished":"2018-02-27T14:22:00.000Z","dateModified":"2020-05-19T06:34:18.437Z","author":{"@type":"Person","name":"Wasim"},"description":"前言自然语言和音频都是前后相互关联的数据，对于这些序列数据需要使用循环神经网络（Recurrent Neural Network，RNN）来进行处理。 使用 RNN 实现的应用包括下图中所示："}</script><link rel="canonical" href="http://www.wangxin123.com/2018/02/27/%E5%BE%AA%E7%8E%AF%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/"><link rel="icon" href="https://hexo-blog-wasim.oss-cn-shenzhen.aliyuncs.com/wu.png"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="wasim&#039;s blog" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="GitHub" href="https://github.com/Wasim37"><i class="fab fa-github"></i></a><a class="navbar-item is-hidden-tablet catalogue" title="目录" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2018-02-27T14:22:00.000Z" title="2018-02-27T14:22:00.000Z">2018-02-27</time><span class="level-item"><a class="link-muted" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></span><span class="level-item">27 分钟 读完 (大约 4067 个字)</span></div></div><h1 class="title is-3 is-size-4-mobile">循环训练模型</h1><div class="content"><h4 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h4><p>自然语言和音频都是前后相互关联的数据，对于这些序列数据需要使用<strong>循环神经网络（Recurrent Neural Network，RNN）</strong>来进行处理。</p>
<p>使用 RNN 实现的应用包括下图中所示：</p>
<p><img src="http://7xvfir.com1.z0.glb.clouddn.com/%E5%BE%AA%E7%8E%AF%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/20180424212312_Examples-of-Sequence-Model.png" alt=""></p>
<a id="more"></a>
<hr>
<h4 id="数学符号"><a href="#数学符号" class="headerlink" title="数学符号"></a>数学符号</h4><p>对于一个序列数据 $x$ ，用符号 $x^{⟨t⟩}$ 来表示这个数据中的第 $t$ 个元素，用 $y^{⟨t⟩}$ 来表示第 $t$ 个标签，用 $T_x$ 和 $T_y$ 来表示输入和输出的长度。对于一段音频，元素可能是其中的几帧；对于一句话，元素可能是一到多个单词。</p>
<p>第 $i$ 个序列数据的第 $t$ 个元素用符号 $x^{(i)⟨t⟩}$，第 $t$ 个标签即为 $y^{(i)⟨t⟩}$。对应即有 $T^{(i)}_x$ 和 $T^{(i)}_y$。</p>
<p>想要表示一个词语，需要先建立一个<strong>词汇表（Vocabulary）</strong>，或者叫<strong>字典（Dictionary）</strong>。将需要表示的所有词语变为一个列向量，可以根据字母顺序排列，然后根据单词在向量中的位置，用 <strong>one-hot 向量（one-hot vector）</strong>来表示该单词的标签：将每个单词编码成一个 $R^{|V| \times 1}$ 向量，其中 |V| 是词汇表中单词的数量。一个单词在词汇表中的索引在该向量对应的元素为 1，其余元素均为 0。</p>
<p>例如，’zebra’排在词汇表的最后一位，因此它的词向量表示为：</p>
<script type="math/tex; mode=display">w^{zebra} = \left [ 0, 0, 0, ..., 1\right ]^T</script><p><strong>补充</strong>：one-hot 向量是最简单的词向量。它的<strong>缺点</strong>是，由于每个单词被表示为完全独立的个体，因此<strong>单词间的相似度无法体现</strong>。例如单词 hotel 和 motel 意思相近，而与 cat 不相似，但是</p>
<script type="math/tex; mode=display">(w^{hotel})^Tw^{motel} = (w^{hotel})^Tw^{cat} = 0</script><hr>
<h4 id="循环神经网络模型"><a href="#循环神经网络模型" class="headerlink" title="循环神经网络模型"></a>循环神经网络模型</h4><p><strong>RNN 的目的是用来处理序列数据</strong>。在传统的神经网络模型中，是从输入层到隐含层再到输出层，层与层之间是全连接的，每层之间的节点是无连接的。但是这种普通的神经网络对于很多问题却无能无力。</p>
<p>比如对于序列数据，使用标准神经网络存在以下问题：</p>
<ul>
<li>对于不同的示例，输入和输出可能有不同的长度，因此输入层和输出层的神经元数量无法固定。</li>
<li>从输入文本的不同位置学到的同一特征无法共享。</li>
<li>模型中的参数太多，计算量太大。</li>
</ul>
<p>为了解决这些问题，引入循环神经网络（Recurrent Neural Network，RNN）。<strong>RNN之所以称为循环神经网路，因为一个序列当前的输出与前面的输出也有关</strong>。</p>
<p>一种循环神经网络的结构如下图所示：</p>
<p><img src="http://7xvfir.com1.z0.glb.clouddn.com/%E5%BE%AA%E7%8E%AF%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/Recurrent-Neural-Network.png" alt=""></p>
<p>当元素 $x^{⟨t⟩}$ 输入对应时间步（Time Step）的隐藏层的同时，<strong>该隐藏层也会接收来自上一时间步的隐藏层的激活值 $a^{⟨t-1⟩}$</strong>，其中 $a^{⟨0⟩}$ 一般直接初始化为零向量。一个时间步输出一个对应的预测结果 $\hat y^{⟨t⟩}$。</p>
<p>循环神经网络从左向右扫描数据，同时每个时间步的参数也是共享的，输入、激活、输出的参数对应为 $W<em>{ax}$、$W</em>{aa}$、$W_{ay}$。</p>
<p>目前我们看到的模型的问题是，只<strong>使用了这个序列中之前的信息来做出预测，即后文没有被使用</strong>。可以通过<strong>双向循环神经网络（Bidirectional RNN，BRNN）</strong>来解决这个问题。</p>
<p>前向传播过程的公式如下：</p>
<p><img src="http://7xvfir.com1.z0.glb.clouddn.com/%E5%BE%AA%E7%8E%AF%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/20180424211053_1.png" alt=""></p>
<p><strong>激活函数 $g_1$ 通常选择 tanh，有时也用 ReLU；g2可选 sigmoid 或 softmax，取决于需要的输出类型。</strong></p>
<p>为了进一步简化公式以方便运算，可以<strong>将 $W<em>{ax}$、$W</em>{aa}$水平并列为一个矩阵 $W_{a}$</strong>，同时 $a^{⟨t-1⟩}$和 $x^{⟨t⟩}$ 堆叠成一个矩阵。则有：</p>
<p><img src="http://7xvfir.com1.z0.glb.clouddn.com/%E5%BE%AA%E7%8E%AF%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/20180424211053_2.png" alt=""></p>
<p><img src="http://7xvfir.com1.z0.glb.clouddn.com/%E5%BE%AA%E7%8E%AF%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/20180425095414.png" alt=""></p>
<hr>
<h4 id="RNN反向传播"><a href="#RNN反向传播" class="headerlink" title="RNN反向传播"></a>RNN反向传播</h4><p>为了计算反向传播过程，需要先定义一个损失函数。单个位置上（或者说单个时间步上）某个单词的预测值的损失函数采用 <strong>交叉熵损失函数</strong>，如下所示：</p>
<script type="math/tex; mode=display">L^{⟨t⟩}(\hat y^{⟨t⟩}, y^{⟨t⟩}) = -y^{⟨t⟩}log\hat y^{⟨t⟩} - (1 - y^{⟨t⟩})log(1-\hat y^{⟨t⟩})</script><p>将单个位置上的损失函数相加，得到整个序列的成本函数如下：</p>
<script type="math/tex; mode=display">J = L(\hat y, y) = \sum^{T_x}_{t=1} L^{⟨t⟩}(\hat y^{⟨t⟩}, y^{⟨t⟩})</script><p>循环神经网络的反向传播被称为 <strong>通过时间反向传播</strong>（Backpropagation through time），因为从右向左计算的过程就像是时间倒流。</p>
<p>更详细的计算公式如下：<br><img src="http://7xvfir.com1.z0.glb.clouddn.com/%E5%BE%AA%E7%8E%AF%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/formula-of-RNN.png" alt=""></p>
<p><strong>附DNN前向反向传播公式</strong>：<br><img src="http://7xvfir.com1.z0.glb.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%89%8D%E5%90%91%E4%BC%A0%E6%92%AD.png" alt="前向传播"><br><img src="http://7xvfir.com1.z0.glb.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD.png" alt="反向传播"></p>
<hr>
<h4 id="不同结构"><a href="#不同结构" class="headerlink" title="不同结构"></a>不同结构</h4><p>某些情况下，输入长度和输出长度不一致。根据所需的输入及输出长度，循环神经网络可分为“一对一”、“多对一”、“多对多”等结构：</p>
<p><img src="http://7xvfir.com1.z0.glb.clouddn.com/%E5%BE%AA%E7%8E%AF%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/Examples-of-RNN-architectures.png" alt=""></p>
<hr>
<h4 id="语言模型"><a href="#语言模型" class="headerlink" title="语言模型"></a>语言模型</h4><p><strong>语言模型</strong>（Language Model）是<strong>根据语言客观事实而进行的语言抽象数学建模，能够估计某个序列中各<font color="red">元素出现的可能性</font></strong>。例如，在一个语音识别系统中，语言模型能够计算两个读音相近的句子为正确结果的概率，以此为依据作出准确判断。</p>
<p>建立语言模型所采用的训练集是一个大型的 <strong>语料库（Corpus）</strong>，指数量众多的句子组成的文本。建立过程的第一步是 <strong>标记化（Tokenize）</strong>，即建立字典；然后将语料库中的每个词表示为对应的 one-hot 向量。另外，需要增加一个额外的标记 EOS（End of Sentence）来表示一个句子的结尾。标点符号可以忽略，也可以加入字典后用 one-hot 向量表示。</p>
<p>对于语料库中部分特殊的、不包含在字典中的词汇，例如人名、地名，可以不必针对这些具体的词，而是在词典中加入一个 UNK（Unique Token）标记来表示。</p>
<p>将标志化后的训练集用于训练 RNN，过程如下图所示：</p>
<p><img src="http://7xvfir.com1.z0.glb.clouddn.com/%E5%BE%AA%E7%8E%AF%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/language-model-RNN-example.png" alt=""></p>
<p>在第一个时间步中，输入的 $a^{⟨0⟩}$ 和 $x^{⟨1⟩}$ 都是零向量，$\hat y^{⟨1⟩}$ 是通过 softmax 预测出的字典中每个词作为第一个词出现的概率；在第二个时间步中，输入的 x⟨2⟩是训练样本的标签中的第一个单词 $y^{⟨1⟩}$（即“cats”）和上一层的激活项 $a^{⟨1⟩}$，输出的 $y^{⟨2⟩}$ 表示的是通过 softmax 预测出的、单词“cats”后面出现字典中的其他每个词的条件概率。以此类推，最后就可以得到整个句子出现的概率。</p>
<p>定义损失函数为：</p>
<script type="math/tex; mode=display">L(\hat y^{⟨t⟩}, y^{⟨t⟩}) = -\sum_t y_i^{⟨t⟩} log \hat y^{⟨t⟩}</script><p>则成本函数为：</p>
<script type="math/tex; mode=display">J = \sum_t L^{⟨t⟩}(\hat y^{⟨t⟩}, y^{⟨t⟩})</script><hr>
<h4 id="采样"><a href="#采样" class="headerlink" title="采样"></a>采样</h4><p>在训练好一个语言模型后，可以通过 <strong>采样（Sample）</strong> 新的序列来了解这个模型中都学习到了一些什么。</p>
<p><img src="http://7xvfir.com1.z0.glb.clouddn.com/%E5%BE%AA%E7%8E%AF%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/Sampling-a-sequence-from-a-trained-RNN.png" alt=""></p>
<p>在第一个时间步输入 $a^{⟨0⟩}$ 和 $x^{⟨1⟩}$ 为零向量，输出预测出的字典中每个词作为第一个词出现的概率，根据 softmax 的分布进行随机采样（np.random.choice），将采样得到的 $\hat y^{⟨1⟩}$ 作为第二个时间步的输入 $x^{⟨2⟩}$ 。以此类推，直到采样到 EOS，最后模型会自动生成一些句子，从这些句子中可以发现模型通过语料库学习到的知识。</p>
<p>这里建立的是基于词汇构建的语言模型。根据需要也可以构建基于字符的语言模型，其优点是不必担心出现未知标识（UNK），其缺点是得到的序列过多过长，并且训练成本高昂。因此，基于词汇构建的语言模型更为常用。</p>
<hr>
<h4 id="RNN-的梯度消失"><a href="#RNN-的梯度消失" class="headerlink" title="RNN 的梯度消失"></a>RNN 的梯度消失</h4><p>The cat,which already ate a bunch of food, was full.<br>The cats,which already ate a bunch of food, were full.</p>
<p>对于以上两个句子，后面的动词单复数形式由前面的名词的单复数形式决定。但是<strong>基本的 RNN 不擅长捕获这种长期依赖关系</strong>。究其原因，由于梯度消失，在反向传播时，后面层的输出误差很难影响到较靠前层的计算，网络很难调整靠前的计算。</p>
<p>在反向传播时，随着层数的增多，梯度不仅可能指数型下降，也有可能指数型上升，即梯度爆炸。不过 <strong>梯度爆炸</strong> 比较容易发现，因为参数会急剧膨胀到数值溢出（可能显示为 NaN）。这时<strong>可以采用梯度修剪（Gradient Clipping）来解决</strong>：观察梯度向量，如果它大于某个阈值，则缩放梯度向量以保证其不会太大。相比之下，<strong>梯度消失问题更难解决</strong>。<font color="red">LSTM 和 GRU 的设计就是为了解决长期依赖问题，都可以作为缓解梯度消失问题的方案</font>。</p>
<hr>
<h4 id="GRU（门控循环单元）"><a href="#GRU（门控循环单元）" class="headerlink" title="GRU（门控循环单元）"></a>GRU（门控循环单元）</h4><p><strong>GRU（Gated Recurrent Units, 门控循环单元）</strong>改善了 RNN 的隐藏层，使其可以更好地捕捉深层连接，并改善了梯度消失问题。</p>
<p>The cat,which already ate a bunch of food, was full.</p>
<p>当我们从左到右读上面这个句子时，GRU 单元有一个新的变量称为 c，代表<strong>记忆细胞</strong>（Memory Cell），其作用是提供记忆的能力，记住例如前文主语是单数还是复数等信息。在时间 t，记忆细胞的值 $c^{⟨t⟩}$ 等于输出的激活值 $a^{⟨t⟩}$；$\tilde c^{⟨t⟩}$ 代表下一个 c 的候选值。$Γ_u$ 代表 <strong>更新门</strong>（Update Gate），用于决定什么时候更新记忆细胞的值。以上结构的具体公式为：</p>
<p><img src="http://7xvfir.com1.z0.glb.clouddn.com/%E5%BE%AA%E7%8E%AF%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/20180424211053_3.png" alt=""></p>
<p><strong>当使用 sigmoid 作为激活函数 $σ$ 来得到 $Γ_u$时，Γu 的值在 0 到 1 的范围内，且大多数时间非常接近于 0 或 1。当 $Γ_u = 1$时，$c^{⟨t⟩}$被更新为 $\tilde c^{⟨t⟩}$，否则保持为 $c^{⟨t-1⟩}$。因为 $Γ_u$ 可以很接近 0，因此 $c^{⟨t⟩}$ 几乎就等于 $c^{⟨t-1⟩}$。在经过很长的序列后，c 的值依然被维持，从而实现“记忆”的功能。</strong></p>
<p>以上实际上是简化过的 GRU 单元，但是蕴涵了 GRU 最重要的思想。完整的 GRU 单元添加了一个新的<strong>相关门（Relevance Gate） $Γ_r$</strong>，表示 $\tilde c^{⟨t⟩}$和 $c^{⟨t⟩}$ 的相关性。因此，表达式改为如下所示：</p>
<p><img src="http://7xvfir.com1.z0.glb.clouddn.com/%E5%BE%AA%E7%8E%AF%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/20180424211053_4.png" alt=""></p>
<p>相关论文：</p>
<ul>
<li><a href="https://arxiv.org/pdf/1409.1259.pdf">ho et al., 2014. On the properties of neural machine translation: Encoder-decoder approaches</a></li>
<li><a href="https://arxiv.org/pdf/1412.3555.pdf">Chung et al., 2014. Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling</a></li>
</ul>
<hr>
<h4 id="LSTM（长短期记忆）"><a href="#LSTM（长短期记忆）" class="headerlink" title="LSTM（长短期记忆）"></a>LSTM（长短期记忆）</h4><p><strong>LSTM（Long Short Term Memory，长短期记忆）</strong>网络比 GRU 更加灵活和强大，它额外引入了<strong>遗忘门（Forget Gate）</strong> $Γ_f$和输出门（Output Gate） $Γ_o$。公式如下：</p>
<p><img src="http://7xvfir.com1.z0.glb.clouddn.com/%E5%BE%AA%E7%8E%AF%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/20180424211053_5.png" alt=""></p>
<p><img src="http://7xvfir.com1.z0.glb.clouddn.com/%E5%BE%AA%E7%8E%AF%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/LSTM.png" alt=""></p>
<p>将多个 LSTM 单元按时间次序连接起来，就得到一个 LSTM 网络。</p>
<p>以上是简化版的 LSTM。在更为常用的版本中，几个门值不仅取决于 $a^{⟨t-1⟩}$ 和 $x^{⟨t⟩}$，有时也可以偷窥上一个记忆细胞输入的值 $c^{⟨t-1⟩}$，这被称为<strong>窥视孔连接（Peephole Connection)</strong>。这时，和 GRU 不同，$c^{⟨t-1⟩}$ 和门值是一对一的。</p>
<font color="red">Tensorflow 官网推荐了一篇 [伟大的文章](#https://colah.github.io/posts/2015-08-Understanding-LSTMs/)， 特别介绍递归神经网络和LSTM</font>

<p>相关论文：<a href="https://www.researchgate.net/publication/13853244_Long_Short-term_Memory">Hochreiter &amp; Schmidhuber 1997. Long short-term memory</a></p>
<hr>
<h4 id="双向循环神经网络（BRNN）"><a href="#双向循环神经网络（BRNN）" class="headerlink" title="双向循环神经网络（BRNN）"></a>双向循环神经网络（BRNN）</h4><p>单向的循环神经网络在某一时刻的预测结果只能使用之前输入的序列信息。<strong>双向循环神经网络（Bidirectional RNN，BRNN）</strong>可以在序列的任意位置使用之前和之后的数据。其工作原理是增加一个反向循环层，结构如下图所示：</p>
<p><img src="http://7xvfir.com1.z0.glb.clouddn.com/%E5%BE%AA%E7%8E%AF%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/BRNN.png" alt=""></p>
<p>因此，有</p>
<script type="math/tex; mode=display">y^{⟨t⟩} = g(W_y[\overrightarrow a^{⟨t⟩},  \overleftarrow a^{⟨t⟩}] + b_y)</script><p>这个改进的方法不仅能用于基本的 RNN，也可以用于 GRU 或 LSTM。<strong>缺点</strong> 是需要完整的序列数据，才能预测任意位置的结果。例如构建语音识别系统，需要等待用户说完并获取整个语音表达，才能处理这段语音并进一步做语音识别。因此，实际应用会有更加复杂的模块。</p>
<hr>
<h4 id="深度循环神经网络（DRNN"><a href="#深度循环神经网络（DRNN" class="headerlink" title="深度循环神经网络（DRNN)"></a>深度循环神经网络（DRNN)</h4><p>循环神经网络的每个时间步上也可以包含多个隐藏层，形成<strong>深度循环神经网络（Deep RNN)</strong>。结构如下图所示：</p>
<p><img src="http://7xvfir.com1.z0.glb.clouddn.com/%E5%BE%AA%E7%8E%AF%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/DRNN.png" alt=""></p>
<p>以 $a^{[2]⟨3⟩}$ 为例，有 $a^{[2]⟨3⟩} = g(W_a^{[2]}[a^{[2]⟨2⟩}, a^{[1]⟨3⟩}] + b_a^{[2]})$</p>
<hr>
<h3 id="代码示例"><a href="#代码示例" class="headerlink" title="代码示例"></a>代码示例</h3><p><a href="https://github.com/Wasim37/deeplearning-assignment/tree/master/5%20%E5%BA%8F%E5%88%97%E6%A8%A1%E5%9E%8B/Week1%20%E5%BE%AA%E7%8E%AF%E5%BA%8F%E5%88%97%E6%A8%A1%E5%9E%8B">循环序列模型</a></p>
</div><div class="article-tags size-small is-uppercase mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/RNN/">RNN</a></div><div class="notification is-danger">You need to set <code>install_url</code> to use ShareThis. Please set it in <code>_config.yml</code>.</div></article></div><div class="card"><div class="card-content"><h3 class="menu-label has-text-centered">喜欢这篇文章？打赏一下作者吧</h3><div class="buttons is-centered"><a class="button is-info donate"><span class="icon is-small"><i class="fab fa-alipay"></i></span><span>支付宝</span><span class="qrcode"><img src="/" alt="支付宝"></span></a><a class="button donate" href="/" style="background-color:rgba(255,128,62,.87);border-color:transparent;color:white;" target="_blank" rel="noopener"><span class="icon is-small"><i class="fas fa-coffee"></i></span><span>送我杯咖啡</span></a><a class="button is-danger donate" href="/" target="_blank" rel="noopener"><span class="icon is-small"><i class="fab fa-patreon"></i></span><span>Patreon</span></a><div class="notification is-danger">You forgot to set the <code>business</code> or <code>currency_code</code> for Paypal. Please set it in <code>_config.yml</code>.</div><a class="button is-success donate"><span class="icon is-small"><i class="fab fa-weixin"></i></span><span>微信</span><span class="qrcode"><img src="/" alt="微信"></span></a></div></div></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2018/03/02/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E4%B8%8E%E8%AF%8D%E5%B5%8C%E5%85%A5/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">自然语言处理与词嵌入</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2018/01/27/%E7%A5%9E%E7%BB%8F%E9%A3%8E%E6%A0%BC%E8%BD%AC%E7%A7%BB/"><span class="level-item">神经风格转移</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">评论</h3><div class="notification is-danger">You forgot to set the <code>shortname</code> for Disqus. Please set it in <code>_config.yml</code>.</div></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-4-widescreen  order-1 is-sticky"><div class="card widget" id="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">目录</h3><ul class="menu-list"><ul class="menu-list"><li><a class="is-flex" href="#前言"><span class="mr-2">1.1</span><span>前言</span></a></li><li><a class="is-flex" href="#数学符号"><span class="mr-2">1.2</span><span>数学符号</span></a></li><li><a class="is-flex" href="#循环神经网络模型"><span class="mr-2">1.3</span><span>循环神经网络模型</span></a></li><li><a class="is-flex" href="#RNN反向传播"><span class="mr-2">1.4</span><span>RNN反向传播</span></a></li><li><a class="is-flex" href="#不同结构"><span class="mr-2">1.5</span><span>不同结构</span></a></li><li><a class="is-flex" href="#语言模型"><span class="mr-2">1.6</span><span>语言模型</span></a></li><li><a class="is-flex" href="#采样"><span class="mr-2">1.7</span><span>采样</span></a></li><li><a class="is-flex" href="#RNN-的梯度消失"><span class="mr-2">1.8</span><span>RNN 的梯度消失</span></a></li><li><a class="is-flex" href="#GRU（门控循环单元）"><span class="mr-2">1.9</span><span>GRU（门控循环单元）</span></a></li><li><a class="is-flex" href="#LSTM（长短期记忆）"><span class="mr-2">1.10</span><span>LSTM（长短期记忆）</span></a></li><li><a class="is-flex" href="#双向循环神经网络（BRNN）"><span class="mr-2">1.11</span><span>双向循环神经网络（BRNN）</span></a></li><li><a class="is-flex" href="#深度循环神经网络（DRNN"><span class="mr-2">1.12</span><span>深度循环神经网络（DRNN)</span></a></li></ul><li><a class="is-flex" href="#代码示例"><span class="mr-2">2</span><span>代码示例</span></a></li></ul></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">分类</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/categories/JAVA/"><span class="level-start"><span class="level-item">JAVA</span></span><span class="level-end"><span class="level-item tag">13</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/%E5%85%B6%E4%BB%96/"><span class="level-start"><span class="level-item">其他</span></span><span class="level-end"><span class="level-item tag">11</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"><span class="level-start"><span class="level-item">大数据</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"><span class="level-start"><span class="level-item">数据库</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"><span class="level-start"><span class="level-item">机器学习</span></span><span class="level-end"><span class="level-item tag">12</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"><span class="level-start"><span class="level-item">深度学习</span></span><span class="level-end"><span class="level-item tag">12</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/"><span class="level-start"><span class="level-item">知识总结</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/%E7%AE%97%E6%B3%95%E5%8F%8A%E7%90%86%E8%AE%BA/"><span class="level-start"><span class="level-item">算法及理论</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/%E8%B5%84%E6%BA%90%E5%85%B1%E4%BA%AB/"><span class="level-start"><span class="level-item">资源共享</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/%E8%BF%90%E7%BB%B4%E9%83%A8%E7%BD%B2/"><span class="level-start"><span class="level-item">运维部署</span></span><span class="level-end"><span class="level-item tag">21</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/%E9%94%99%E8%AF%AF%E9%9B%86%E9%94%A6/"><span class="level-start"><span class="level-item">错误集锦</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li></ul></div></div></div><div class="card widget"><div class="card-content"><h3 class="menu-label">最新文章</h3><article class="media"><div class="media-content size-small"><p><time dateTime="2020-05-19T11:33:11.208Z">2020-05-19</time></p><p class="title is-6"><a class="link-muted" href="/2020/05/19/hello-world/">Hello World</a></p><p class="is-uppercase"></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2019-01-01T14:22:00.000Z">2019-01-01</time></p><p class="title is-6"><a class="link-muted" href="/2019/01/01/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">深度学习笔记</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/">知识总结</a></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2019-01-01T14:22:00.000Z">2019-01-01</time></p><p class="title is-6"><a class="link-muted" href="/2019/01/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">机器学习笔记</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/">知识总结</a></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2018-07-10T14:22:00.000Z">2018-07-10</time></p><p class="title is-6"><a class="link-muted" href="/2018/07/10/%E5%90%B4%E6%81%A9%E8%BE%BE%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E8%AF%BE%E5%A0%82%E7%AC%94%E8%AE%B0/">吴恩达目标检测课堂笔记</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2018-03-10T14:22:00.000Z">2018-03-10</time></p><p class="title is-6"><a class="link-muted" href="/2018/03/10/%E5%BA%8F%E5%88%97%E6%A8%A1%E5%9E%8B%E4%B8%8E%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/">序列模型与注意力机制</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></p></div></article></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">归档</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/archives/2020/05/"><span class="level-start"><span class="level-item">五月 2020</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2019/01/"><span class="level-start"><span class="level-item">一月 2019</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2018/07/"><span class="level-start"><span class="level-item">七月 2018</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2018/03/"><span class="level-start"><span class="level-item">三月 2018</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2018/02/"><span class="level-start"><span class="level-item">二月 2018</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2018/01/"><span class="level-start"><span class="level-item">一月 2018</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2017/12/"><span class="level-start"><span class="level-item">十二月 2017</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2017/11/"><span class="level-start"><span class="level-item">十一月 2017</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2017/10/"><span class="level-start"><span class="level-item">十月 2017</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2017/09/"><span class="level-start"><span class="level-item">九月 2017</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2017/05/"><span class="level-start"><span class="level-item">五月 2017</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2017/04/"><span class="level-start"><span class="level-item">四月 2017</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2017/03/"><span class="level-start"><span class="level-item">三月 2017</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2017/02/"><span class="level-start"><span class="level-item">二月 2017</span></span><span class="level-end"><span class="level-item tag">9</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2017/01/"><span class="level-start"><span class="level-item">一月 2017</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2016/12/"><span class="level-start"><span class="level-item">十二月 2016</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2016/11/"><span class="level-start"><span class="level-item">十一月 2016</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2016/10/"><span class="level-start"><span class="level-item">十月 2016</span></span><span class="level-end"><span class="level-item tag">9</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2016/09/"><span class="level-start"><span class="level-item">九月 2016</span></span><span class="level-end"><span class="level-item tag">12</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2016/08/"><span class="level-start"><span class="level-item">八月 2016</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2016/07/"><span class="level-start"><span class="level-item">七月 2016</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2016/06/"><span class="level-start"><span class="level-item">六月 2016</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2016/05/"><span class="level-start"><span class="level-item">五月 2016</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2016/04/"><span class="level-start"><span class="level-item">四月 2016</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li></ul></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">标签</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/2pc/"><span class="tag">2pc</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/3pc/"><span class="tag">3pc</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ACID/"><span class="tag">ACID</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Attention-Model/"><span class="tag">Attention Model</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/BASE/"><span class="tag">BASE</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Batch-Normalization/"><span class="tag">Batch Normalization</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CAP/"><span class="tag">CAP</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CNN/"><span class="tag">CNN</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Druid/"><span class="tag">Druid</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/EM/"><span class="tag">EM</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Flume/"><span class="tag">Flume</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/HDFS/"><span class="tag">HDFS</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/JVM/"><span class="tag">JVM</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Lambda/"><span class="tag">Lambda</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/MapReduce/"><span class="tag">MapReduce</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Metrics/"><span class="tag">Metrics</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/NLP/"><span class="tag">NLP</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Open-XML-SDK-2-0-Productivity-Tool/"><span class="tag">Open XML SDK 2.0 Productivity Tool</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Percona-Xtrabackup/"><span class="tag">Percona Xtrabackup</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/RNN/"><span class="tag">RNN</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/SVM/"><span class="tag">SVM</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Sqoop/"><span class="tag">Sqoop</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/StyleTransfer/"><span class="tag">StyleTransfer</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Swagger/"><span class="tag">Swagger</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/VPSMate/"><span class="tag">VPSMate</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/YOLO/"><span class="tag">YOLO</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/aof/"><span class="tag">aof</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/atlas/"><span class="tag">atlas</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/concurrent/"><span class="tag">concurrent</span><span class="tag is-grey-lightest">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/elk/"><span class="tag">elk</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/github/"><span class="tag">github</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/hadoop/"><span class="tag">hadoop</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/hexo/"><span class="tag">hexo</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/hive/"><span class="tag">hive</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/jdk/"><span class="tag">jdk</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/jenkins/"><span class="tag">jenkins</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/lambda/"><span class="tag">lambda</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/linux/"><span class="tag">linux</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/mysql/"><span class="tag">mysql</span><span class="tag is-grey-lightest">10</span></a></div><div class="control"><a class="tags has-addons" href="/tags/redis/"><span class="tag">redis</span><span class="tag is-grey-lightest">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/shiro/"><span class="tag">shiro</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/sonar/"><span class="tag">sonar</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/tcp/"><span class="tag">tcp</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/word2vec/"><span class="tag">word2vec</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/word%E8%A7%A3%E6%9E%90/"><span class="tag">word解析</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/zabbix/"><span class="tag">zabbix</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E4%B8%BB%E9%A2%98%E6%A8%A1%E5%9E%8B/"><span class="tag">主题模型</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/"><span class="tag">人脸识别</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%86%B3%E7%AD%96%E6%A0%91/"><span class="tag">决策树</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/"><span class="tag">分布式事务</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E7%AE%97%E6%B3%95/"><span class="tag">分布式算法</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%8D%B7%E7%A7%AF/"><span class="tag">卷积</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%90%B4%E6%81%A9%E8%BE%BE/"><span class="tag">吴恩达</span><span class="tag is-grey-lightest">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%A2%9E%E9%87%8F%E5%A4%87%E4%BB%BD/"><span class="tag">增量备份</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%A4%87%E4%BB%BD/"><span class="tag">备份</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"><span class="tag">大数据</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%95%99%E7%A8%8B/"><span class="tag">大数据教程</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%AE%89%E5%85%A8/"><span class="tag">安全</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%AE%8C%E5%85%A8%E5%A4%87%E4%BB%BD/"><span class="tag">完全备份</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7/"><span class="tag">微信公众号</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%95%99%E7%A8%8B/"><span class="tag">微服务教程</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%80%A7%E8%83%BD%E6%A3%80%E6%B5%8B/"><span class="tag">性能检测</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%81%A2%E5%A4%8D/"><span class="tag">恢复</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%8F%90%E5%8D%87%E7%AE%97%E6%B3%95/"><span class="tag">提升算法</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"><span class="tag">数据库</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"><span class="tag">机器学习</span><span class="tag is-grey-lightest">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%95%99%E7%A8%8B/"><span class="tag">机器学习教程</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"><span class="tag">深度学习</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%88%AC%E8%99%AB/"><span class="tag">爬虫</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/"><span class="tag">特征工程</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%96%91%E9%9A%BE%E6%9D%82%E7%97%87/"><span class="tag">疑难杂症</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%AE%97%E6%B3%95%E5%A4%8D%E6%9D%82%E5%BA%A6/"><span class="tag">算法复杂度</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"><span class="tag">线性回归</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%BA%BF%E7%A8%8B%E6%B1%A0/"><span class="tag">线程池</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%BB%8F%E5%85%B8%E7%BD%91%E7%BB%9C/"><span class="tag">经典网络</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%BC%96%E7%A0%81%E8%A7%84%E8%8C%83/"><span class="tag">编码规范</span><span class="tag is-grey-lightest">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%81%9A%E7%B1%BB/"><span class="tag">聚类</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%84%9A%E6%9C%AC/"><span class="tag">脚本</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%96%9B%E5%85%86%E4%B8%B0%E7%9A%84%E5%8C%97%E5%A4%A7%E7%BB%8F%E6%B5%8E%E5%AD%A6%E8%AF%BE/"><span class="tag">薛兆丰的北大经济学课</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%99%9A%E6%8B%9F%E6%9C%BA/"><span class="tag">虚拟机</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%A1%A8%E6%89%A9%E5%B1%95/"><span class="tag">表扩展</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%B4%9D%E5%8F%B6%E6%96%AF/"><span class="tag">贝叶斯</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%BE%B9%E7%BC%98%E6%A3%80%E6%B5%8B/"><span class="tag">边缘检测</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%BF%90%E7%BB%B4/"><span class="tag">运维</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/"><span class="tag">逻辑回归</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97/"><span class="tag">随机森林</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E9%9A%90%E9%A9%AC%E5%B0%94%E7%A7%91%E5%A4%AB%E6%A8%A1%E5%9E%8B/"><span class="tag">隐马尔科夫模型</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E9%9B%86%E5%90%88/"><span class="tag">集合</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1/"><span class="tag">面向对象</span><span class="tag is-grey-lightest">1</span></a></div></div></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">链接</h3><ul class="menu-list"><li><a class="level is-mobile is-mobile" href="https://hexo.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Hexo</span></span><span class="level-right"><span class="level-item tag">hexo.io</span></span></a></li><li><a class="level is-mobile is-mobile" href="https://bulma.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Bulma</span></span><span class="level-right"><span class="level-item tag">bulma.io</span></span></a></li></ul></div></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="wasim&#039;s blog" height="28"></a><p class="size-small"><span>&copy; 2020 Wasim</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/Wasim"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script>moment.locale("zh-CN");</script><script>var IcarusThemeSettings = {
            site: {
                url: 'http://www.wangxin123.com',
                external_link: {"enable":true,"exclude":[]}
            },
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" defer></script><script>window.addEventListener("load", function() {
            document.querySelectorAll('[role="article"] > .content').forEach(function(element) {
                renderMathInElement(element);
            });
        });</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script></body></html>