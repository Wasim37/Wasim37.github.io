<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="generator" content="Hexo 4.2.1"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>星空str</title><meta description="ai,机器学习,深度学习,算法,leetcode,java"><meta property="og:type" content="blog"><meta property="og:title" content="Wasim37"><meta property="og:url" content="https://wangxin123.com/"><meta property="og:site_name" content="Wasim37"><meta property="og:description" content="ai,机器学习,深度学习,算法,leetcode,java"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://hexo-blog-wasim.oss-cn-shenzhen.aliyuncs.com/blog_avatar_lufei.png"><meta property="article:author" content="Wasim37"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="https://hexo-blog-wasim.oss-cn-shenzhen.aliyuncs.com/blog_avatar_lufei.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://wangxin123.com/"},"headline":"Wasim37","image":["https://hexo-blog-wasim.oss-cn-shenzhen.aliyuncs.com/blog_avatar_lufei.png"],"author":{"@type":"Person","name":"Wasim37"},"description":"ai,机器学习,深度学习,算法,leetcode,java"}</script><link rel="alternative" href="/atom.xml" title="星空str" type="application/atom+xml"><link rel="icon" href="https://hexo-blog-wasim.oss-cn-shenzhen.aliyuncs.com/wu.png"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.0/css/all.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Ubuntu:400,600|Source+Code+Pro"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-dark.css"><link rel="stylesheet" href="//fonts.googleapis.com/css?family=Monda:300,300italic,400,400italic,700,700italic|Roboto Slab:300,300italic,400,400italic,700,700italic|Microsoft YaHei:300,300italic,400,400italic,700,700italic|PT Mono:300,300italic,400,400italic,700,700italic&amp;amp;subset=latin,latin-ext"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" defer></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><link rel="stylesheet" href="/css/style.css"><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="/js/globalUtils.js"></script></head><body class="is-3-column has-navbar-fixed-top"><nav class="navbar navbar-main is-fixed-top"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="https://hexo-blog-wasim.oss-cn-shenzhen.aliyuncs.com/logo.svg" alt="星空str" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item is-active" href="/">首页</a><a class="navbar-item" href="/archives">归档</a><a class="navbar-item" href="/categories">分类</a><a class="navbar-item" href="/tags">标签</a><a class="navbar-item" href="/about">关于</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="GitHub" href="https://github.com/wasim37"><i class="fab fa-github"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><script type="text/javascript" src="/js/theme-setting.js"></script><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2021-01-01T16:00:00.000Z">2021-01-02</time><a class="commentCountImg" href="/2021/01/02/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/#comment-container"><span class="display-none-class">f97a32ffc3c51bf2f4626c8e8b3f93fd</span><img class="not-gallery-item" src="https://hexo-blog-wasim.oss-cn-shenzhen.aliyuncs.com/chat.svg"> <span class="commentCount" id="f97a32ffc3c51bf2f4626c8e8b3f93fd"> 0</span>    </a><span class="level-item"><i class="fas fa-folder-open has-text-grey"> </i><a class="link-muted" href="/categories/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/">知识总结</a></span><span class="level-item">2 小时 读完 (大约 20324 个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/01/02/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">深度学习笔记</a></h1><div class="content"><h3 id="什么是梯度消失和梯度爆炸，分别会引发什么问题"><a href="#什么是梯度消失和梯度爆炸，分别会引发什么问题" class="headerlink" title="什么是梯度消失和梯度爆炸，分别会引发什么问题"></a>什么是梯度消失和梯度爆炸，分别会引发什么问题</h3><p>我们知道神经网络在训练过程中会利用梯度对网络的权重进行更新迭代。<br>当梯度出现指数级递减或指数递增时，称为梯度消失或者梯度爆炸。</p>
<p>假定激活函数 $g(z) = z$, 令 $b^{[l]} = 0$，对于目标输出有：<br>$\hat{y} = W^{[L]}W^{[L-1]}…W^{[2]}W^{[1]}X$<br>1）对于 W[l]的值小于 1 的情况，激活函数的值将以指数级递减<br>2）对于 W[l]的值大于 1 的情况，激活函数的值将以指数级递增<br>同理的情况会出现在反向求导。</p>
<p>梯度消失时，权重更新缓慢，训练难度大大增加。梯度消失相对梯度爆炸更常见。<br>梯度爆炸时，权重大幅更新，网络变得不稳定。较好的情况是网络无法利用训练数据学习，最差的情况是权值增大溢出，变成网络无法更新的 NaN 值。</p></div><div class="level is-mobile is-flex"><div class="level-start"><div class="is-uppercase article-more button is-small size-small"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted mr-2" rel="tag" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></div></div><div class="level-start"><div class="level-item"><a class="article-more button is-small size-small link-muted" href="/2021/01/02/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/#more"><i class="fas fa-book-reader has-text-grey"> </i>阅读更多&gt;&gt;</a></div></div></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2021-01-01T16:00:00.000Z">2021-01-02</time><a class="commentCountImg" href="/2021/01/02/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/#comment-container"><span class="display-none-class">c7c4d37df34925b7c1e623d6b2872f06</span><img class="not-gallery-item" src="https://hexo-blog-wasim.oss-cn-shenzhen.aliyuncs.com/chat.svg"> <span class="commentCount" id="c7c4d37df34925b7c1e623d6b2872f06"> 0</span>    </a><span class="level-item"><i class="fas fa-folder-open has-text-grey"> </i><a class="link-muted" href="/categories/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/">知识总结</a></span><span class="level-item">几秒 读完 (大约 25 个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/01/02/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">其他</a></h1><div class="content"><ul>
<li><a href="https://zhuanlan.zhihu.com/p/101550272">CPU、GPU和TPU区别</a></li>
<li><a href="http://www.pythondoc.com/flask/index.html">python Flask WEB微框架</a></li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2021-01-01T14:22:00.000Z">2021-01-01</time><a class="commentCountImg" href="/2021/01/01/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/#comment-container"><span class="display-none-class">441572d694a28adc232a1d6d8c45da2e</span><img class="not-gallery-item" src="https://hexo-blog-wasim.oss-cn-shenzhen.aliyuncs.com/chat.svg"> <span class="commentCount" id="441572d694a28adc232a1d6d8c45da2e"> 0</span>    </a><span class="level-item"><i class="fas fa-folder-open has-text-grey"> </i><a class="link-muted" href="/categories/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/">知识总结</a></span><span class="level-item">1 小时 读完 (大约 13067 个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/01/01/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">机器学习笔记</a></h1><div class="content"><ul>
<li><a href="http://www.ai-start.com/ml2014/html/week8.html#header-n186">PCA_吴恩达</a></li>
<li><a href="http://www.ai-start.com/ml2014/html/week9.html#header-n5">异常值检测_吴恩达</a></li>
<li><a href="http://www.ai-start.com/ml2014/html/week9.html#header-n279">推荐系统_吴恩达</a></li>
<li><a href="https://www.zhihu.com/question/19971859">协同过滤和基于内容推荐有什么区别</a></li>
</ul>
<ul>
<li><a href="https://www.zhihu.com/question/23259302">如何准备机器学习工程师的面试</a></li>
<li><a href="https://www.zhihu.com/question/62482926">如何判断某个人的机器学习水平</a></li>
</ul>
<hr>
<h1 id="理解矩阵"><a href="#理解矩阵" class="headerlink" title="理解矩阵"></a>理解矩阵</h1><p>有人说，矩阵的本质就是线性方程式，两者是一一对应关系<br>链接：<a href="http://www.ruanyifeng.com/blog/2015/09/matrix-multiplication.html">http://www.ruanyifeng.com/blog/2015/09/matrix-multiplication.html</a></p>
<p>也有人说，矩阵的本质是运动的描述。简而言之，就是在线性空间中选定基之后，向量刻画对象，矩阵刻画对象的运动，用矩阵与向量的乘法施加运动。<br>链接：<a href="https://pan.baidu.com/s/1BLyrQH5_VAw832jKkCgpBA">https://pan.baidu.com/s/1BLyrQH5_VAw832jKkCgpBA</a> 密码：ljwq</p></div><div class="level is-mobile is-flex"><div class="level-start"><div class="is-uppercase article-more button is-small size-small"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted mr-2" rel="tag" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></div></div><div class="level-start"><div class="level-item"><a class="article-more button is-small size-small link-muted" href="/2021/01/01/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/#more"><i class="fas fa-book-reader has-text-grey"> </i>阅读更多&gt;&gt;</a></div></div></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2020-04-10T16:00:00.000Z">2020-04-11</time><a class="commentCountImg" href="/2020/04/11/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/%E4%BB%8ENB%E5%88%B0%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/#comment-container"><span class="display-none-class">9d954c459b332655cb9c9baf7f78cb0e</span><img class="not-gallery-item" src="https://hexo-blog-wasim.oss-cn-shenzhen.aliyuncs.com/chat.svg"> <span class="commentCount" id="9d954c459b332655cb9c9baf7f78cb0e"> 0</span>    </a><span class="level-item"><i class="fas fa-folder-open has-text-grey"> </i><a class="link-muted" href="/categories/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/">自然语言处理</a></span><span class="level-item">42 分钟 读完 (大约 6354 个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/04/11/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/%E4%BB%8ENB%E5%88%B0%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/">从NB到语言模型</a></h1><div class="content"><p><a name="n4jr6"></a></p>
<h2 id="1-引言：朴素贝叶斯的局限性"><a href="#1-引言：朴素贝叶斯的局限性" class="headerlink" title="1. 引言：朴素贝叶斯的局限性"></a>1. 引言：朴素贝叶斯的局限性</h2><p>我们知道朴素贝叶斯的局限性来源于其条件独立假设，它将文本看成是词袋子模型，不考虑词语之间的顺序信息，就会把“武松打死了老虎”与“老虎打死了武松”认作是一个意思。那么有没有一种方法提高其对词语顺序的识别能力呢？有，就是这里要提到的N-gram语言模型。<br><a name="jTi2S"></a></p>
<h2 id="2-N-gram语言模型是啥？"><a href="#2-N-gram语言模型是啥？" class="headerlink" title="2. N-gram语言模型是啥？"></a>2. N-gram语言模型是啥？</h2><p><a name="odXF2"></a></p>
<h3 id="2-1从假设性独立到联合概率链规则"><a href="#2-1从假设性独立到联合概率链规则" class="headerlink" title="2.1从假设性独立到联合概率链规则"></a>2.1从假设性独立到联合概率链规则</h3><p>照抄我们垃圾邮件识别中的条件独立假设，长这个样子：</p>
<blockquote>
<script type="math/tex; mode=display">P(（“我”,“司”,“可”,“办理”,“正规发票”,“保真”,“增值税”,“发票”,“点数”,“优惠”)|S)</script><script type="math/tex; mode=display">
=P(“我”|S)×P(“司”|S)×P(“可”|S)×P(“办理”|S)×P(“正规发票”|S)</script><script type="math/tex; mode=display">×P(“保真”|S)×P(“增值税”|S)×P(“发票”|S)×P(“点数”|S)×P(“优惠”|S)</script></blockquote>
<p>为了简化起见，我们以字母<script type="math/tex">x_i</script>表示每一个词语，并且先不考虑条件“S”。于是上式就变成了下面的独立性公式。</p>
<blockquote>
<script type="math/tex; mode=display">P(x_1,x_2,x_3,x_4,x_5,x_6,x_7,x_8,x_9,x_{10})</script><script type="math/tex; mode=display">=P(x_1)P(x_2)P(x_3)P(x_4)P(x_5)P(x_6)P(x_7)P(x_8)P(x_9)P(x_{10})</script><script type="math/tex; mode=display">=P(“我”)P(“司”)P(“可”)P(“办理”)...P(“优惠”)</script></blockquote></div><div class="level is-mobile is-flex"><div class="level-start"><div class="is-uppercase article-more button is-small size-small"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted mr-2" rel="tag" href="/tags/%E8%B4%9D%E5%8F%B6%E6%96%AF/">贝叶斯</a></div></div><div class="level-start"><div class="level-item"><a class="article-more button is-small size-small link-muted" href="/2020/04/11/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/%E4%BB%8ENB%E5%88%B0%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/#more"><i class="fas fa-book-reader has-text-grey"> </i>阅读更多&gt;&gt;</a></div></div></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2020-04-10T16:00:00.000Z">2020-04-11</time><a class="commentCountImg" href="/2020/04/11/%E7%BB%8F%E5%85%B8%E6%A8%A1%E5%9E%8B/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF/#comment-container"><span class="display-none-class">3087bd0d792cda5e28cfbb3cee7681f0</span><img class="not-gallery-item" src="https://hexo-blog-wasim.oss-cn-shenzhen.aliyuncs.com/chat.svg"> <span class="commentCount" id="3087bd0d792cda5e28cfbb3cee7681f0"> 0</span>    </a><span class="level-item"><i class="fas fa-folder-open has-text-grey"> </i><a class="link-muted" href="/categories/%E7%BB%8F%E5%85%B8%E6%A8%A1%E5%9E%8B/">经典模型</a></span><span class="level-item">2 小时 读完 (大约 13513 个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/04/11/%E7%BB%8F%E5%85%B8%E6%A8%A1%E5%9E%8B/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF/">朴素贝叶斯</a></h1><div class="content"><h2 id="1-引言"><a href="#1-引言" class="headerlink" title="1. 引言"></a>1. 引言</h2><p>贝叶斯方法是一个历史悠久，有着坚实的理论基础的方法，同时处理很多问题时直接而又高效，很多高级自然语言处理模型也可以从它演化而来。因此，学习贝叶斯方法，是研究自然语言处理问题的一个非常好的切入口。</p>
<h2 id="2-贝叶斯公式"><a href="#2-贝叶斯公式" class="headerlink" title="2. 贝叶斯公式"></a>2. 贝叶斯公式</h2><p>贝叶斯公式就一行：</p>
<blockquote>
<script type="math/tex; mode=display">P(Y|X)=\frac{P(X|Y)P(Y)}{P(X)}</script></blockquote>
<p>而它其实是由以下的联合概率公式推导出来：</p>
<blockquote>
<script type="math/tex; mode=display">P(Y,X) = P(Y|X)P(X)=P(X|Y)P(Y)</script></blockquote>
<p>其中<script type="math/tex">P(Y)</script>叫做先验概率，<script type="math/tex">P(Y|X)</script>叫做后验概率，<script type="math/tex">P(Y,X)</script>叫做联合概率。<br>贝叶斯最核心的公式就这么些。</p></div><div class="level is-mobile is-flex"><div class="level-start"><div class="is-uppercase article-more button is-small size-small"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted mr-2" rel="tag" href="/tags/%E8%B4%9D%E5%8F%B6%E6%96%AF/">贝叶斯</a></div></div><div class="level-start"><div class="level-item"><a class="article-more button is-small size-small link-muted" href="/2020/04/11/%E7%BB%8F%E5%85%B8%E6%A8%A1%E5%9E%8B/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF/#more"><i class="fas fa-book-reader has-text-grey"> </i>阅读更多&gt;&gt;</a></div></div></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2018-07-10T14:22:00.000Z">2018-07-10</time><a class="commentCountImg" href="/2018/07/10/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E5%90%B4%E6%81%A9%E8%BE%BE%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E8%AF%BE%E5%A0%82%E7%AC%94%E8%AE%B0/#comment-container"><span class="display-none-class">a3f0edc489ec6a72c6ded10f3561dfff</span><img class="not-gallery-item" src="https://hexo-blog-wasim.oss-cn-shenzhen.aliyuncs.com/chat.svg"> <span class="commentCount" id="a3f0edc489ec6a72c6ded10f3561dfff"> 0</span>    </a><span class="level-item"><i class="fas fa-folder-open has-text-grey"> </i><a class="link-muted" href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/">计算机视觉</a></span><span class="level-item">22 分钟 读完 (大约 3254 个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2018/07/10/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E5%90%B4%E6%81%A9%E8%BE%BE%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E8%AF%BE%E5%A0%82%E7%AC%94%E8%AE%B0/">吴恩达目标检测课堂笔记</a></h1><div class="content"><p>目标检测是计算机视觉领域中一个新兴的应用方向，其任务是对输入图像进行分类的同时，检测图像中是否包含某些目标，并对他们准确定位并标识。</p>
<p>本文所涉及的目标检测算法是 Ng 课堂上所讲的 YOLO，除此之外流行的还有 RCNN、Fast RCNN、Faster RCNN 和 SSD。</p>
<p>相关链接：</p>
<ul>
<li><a href="https://github.com/Wasim37/deeplearning-assignment/tree/master/4%20%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/Week3%20%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B">代码示例</a></li>
<li><a href="https://pjreddie.com/darknet/yolo/">YOLO: Real-Time Object Detection</a></li>
<li><a href="https://pan.baidu.com/s/1N-9TWlrMSjAH9a5zeF5KOw">目标检测 ppt 文件</a> 密码：kt2h</li>
<li><a href="https://github.com/Wasim37/SSD-Tensorflow">SSD github项目</a></li>
</ul></div><div class="level is-mobile is-flex"><div class="level-start"><div class="is-uppercase article-more button is-small size-small"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted mr-2" rel="tag" href="/tags/CNN/">CNN</a><a class="link-muted mr-2" rel="tag" href="/tags/YOLO/">YOLO</a></div></div><div class="level-start"><div class="level-item"><a class="article-more button is-small size-small link-muted" href="/2018/07/10/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E5%90%B4%E6%81%A9%E8%BE%BE%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E8%AF%BE%E5%A0%82%E7%AC%94%E8%AE%B0/#more"><i class="fas fa-book-reader has-text-grey"> </i>阅读更多&gt;&gt;</a></div></div></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2018-03-10T14:22:00.000Z">2018-03-10</time><a class="commentCountImg" href="/2018/03/10/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/%E5%BA%8F%E5%88%97%E6%A8%A1%E5%9E%8B%E4%B8%8E%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/#comment-container"><span class="display-none-class">dfdbae100df440537460ac904eb23fdd</span><img class="not-gallery-item" src="https://hexo-blog-wasim.oss-cn-shenzhen.aliyuncs.com/chat.svg"> <span class="commentCount" id="dfdbae100df440537460ac904eb23fdd"> 0</span>    </a><span class="level-item"><i class="fas fa-folder-open has-text-grey"> </i><a class="link-muted" href="/categories/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">神经网络</a></span><span class="level-item">25 分钟 读完 (大约 3788 个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2018/03/10/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/%E5%BA%8F%E5%88%97%E6%A8%A1%E5%9E%8B%E4%B8%8E%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/">序列模型与注意力机制</a></h1><div class="content"><h3 id="Seq2Seq-模型"><a href="#Seq2Seq-模型" class="headerlink" title="Seq2Seq 模型"></a>Seq2Seq 模型</h3><div>
$$
i\hbar\frac{\partial}{\partial t}\psi=-\frac{\hbar^2}{2m}\nabla^2\psi+V\psi
$$
</div>

<p><strong>Seq2Seq（Sequence-to-Sequence）</strong>模型能够应用于机器翻译、语音识别等各种序列到序列的转换问题。一个 Seq2Seq 模型包含<strong>编码器（Encoder）</strong>和<strong>解码器（Decoder）</strong>两部分，它们通常是两个不同的 RNN。如下图所示，将编码器的输出作为解码器的输入，由解码器负责输出正确的翻译结果。</p></div><div class="level is-mobile is-flex"><div class="level-start"><div class="is-uppercase article-more button is-small size-small"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted mr-2" rel="tag" href="/tags/RNN/">RNN</a><a class="link-muted mr-2" rel="tag" href="/tags/Attention-Model/">Attention Model</a></div></div><div class="level-start"><div class="level-item"><a class="article-more button is-small size-small link-muted" href="/2018/03/10/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/%E5%BA%8F%E5%88%97%E6%A8%A1%E5%9E%8B%E4%B8%8E%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/#more"><i class="fas fa-book-reader has-text-grey"> </i>阅读更多&gt;&gt;</a></div></div></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2018-03-02T14:22:00.000Z">2018-03-02</time><a class="commentCountImg" href="/2018/03/02/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E4%B8%8E%E8%AF%8D%E5%B5%8C%E5%85%A5/#comment-container"><span class="display-none-class">8a7d5fd43ac126066de9375b5a995100</span><img class="not-gallery-item" src="https://hexo-blog-wasim.oss-cn-shenzhen.aliyuncs.com/chat.svg"> <span class="commentCount" id="8a7d5fd43ac126066de9375b5a995100"> 0</span>    </a><span class="level-item"><i class="fas fa-folder-open has-text-grey"> </i><a class="link-muted" href="/categories/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/">自然语言处理</a></span><span class="level-item">23 分钟 读完 (大约 3403 个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2018/03/02/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E4%B8%8E%E8%AF%8D%E5%B5%8C%E5%85%A5/">自然语言处理与词嵌入</a></h1><div class="content"><h3 id="词嵌入"><a href="#词嵌入" class="headerlink" title="词嵌入"></a>词嵌入</h3><p>one-hot 向量将每个单词表示为完全独立的个体，不同词向量都是正交的，因此单词间的相似度无法体现。</p>
<p>换用特征化表示方法能够解决这一问题。我们可以通过用语义特征作为维度来表示一个词，因此语义相近的词，其词向量也相近。</p>
<p>将高维的词嵌入“嵌入”到一个二维空间里，就可以进行可视化。常用的一种可视化算法是 t-SNE 算法。在通过复杂而非线性的方法映射到二维空间后，每个词会根据语义和相关程度聚在一起。相关论文：<a href="https://www.seas.harvard.edu/courses/cs281/papers/tsne.pdf">van der Maaten and Hinton., 2008. Visualizing Data using t-SNE</a></p>
<p><strong>词嵌入（Word Embedding）</strong>是 NLP 中语言模型与表征学习技术的统称，概念上而言，它是指把一个维数为所有词的数量的高维空间（one-hot 形式表示的词）“嵌入”到一个维数低得多的连续向量空间中，每个单词或词组被映射为实数域上的向量。对大量词汇进行词嵌入后获得的词向量，可用于完成 <strong>命名实体识别（Named Entity Recognition）</strong> 等任务。</p></div><div class="level is-mobile is-flex"><div class="level-start"><div class="is-uppercase article-more button is-small size-small"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted mr-2" rel="tag" href="/tags/word2vec/">word2vec</a></div></div><div class="level-start"><div class="level-item"><a class="article-more button is-small size-small link-muted" href="/2018/03/02/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E4%B8%8E%E8%AF%8D%E5%B5%8C%E5%85%A5/#more"><i class="fas fa-book-reader has-text-grey"> </i>阅读更多&gt;&gt;</a></div></div></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2018-02-27T14:22:00.000Z">2018-02-27</time><a class="commentCountImg" href="/2018/02/27/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/%E5%BE%AA%E7%8E%AF%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/#comment-container"><span class="display-none-class">bb2ddc8b83876904e2d3fca244ea145a</span><img class="not-gallery-item" src="https://hexo-blog-wasim.oss-cn-shenzhen.aliyuncs.com/chat.svg"> <span class="commentCount" id="bb2ddc8b83876904e2d3fca244ea145a"> 0</span>    </a><span class="level-item"><i class="fas fa-folder-open has-text-grey"> </i><a class="link-muted" href="/categories/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">神经网络</a></span><span class="level-item">27 分钟 读完 (大约 4101 个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2018/02/27/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/%E5%BE%AA%E7%8E%AF%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/">循环训练模型</a></h1><div class="content"><h4 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h4><p>自然语言和音频都是前后相互关联的数据，对于这些序列数据需要使用<strong>循环神经网络（Recurrent Neural Network，RNN）</strong>来进行处理。</p>
<p>使用 RNN 实现的应用包括下图中所示：</p>
<p><img src="https://hexo-blog-wasim.oss-cn-shenzhen.aliyuncs.com/%E5%BE%AA%E7%8E%AF%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/20180424212312_Examples-of-Sequence-Model.png" alt=""></p></div><div class="level is-mobile is-flex"><div class="level-start"><div class="is-uppercase article-more button is-small size-small"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted mr-2" rel="tag" href="/tags/RNN/">RNN</a></div></div><div class="level-start"><div class="level-item"><a class="article-more button is-small size-small link-muted" href="/2018/02/27/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/%E5%BE%AA%E7%8E%AF%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/#more"><i class="fas fa-book-reader has-text-grey"> </i>阅读更多&gt;&gt;</a></div></div></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2018-01-27T14:22:00.000Z">2018-01-27</time><a class="commentCountImg" href="/2018/01/27/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/%E7%A5%9E%E7%BB%8F%E9%A3%8E%E6%A0%BC%E8%BD%AC%E7%A7%BB/#comment-container"><span class="display-none-class">9d3a8e12b5cf995ceb022a73aa151bfe</span><img class="not-gallery-item" src="https://hexo-blog-wasim.oss-cn-shenzhen.aliyuncs.com/chat.svg"> <span class="commentCount" id="9d3a8e12b5cf995ceb022a73aa151bfe"> 0</span>    </a><span class="level-item"><i class="fas fa-folder-open has-text-grey"> </i><a class="link-muted" href="/categories/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">神经网络</a></span><span class="level-item">9 分钟 读完 (大约 1384 个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2018/01/27/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/%E7%A5%9E%E7%BB%8F%E9%A3%8E%E6%A0%BC%E8%BD%AC%E7%A7%BB/">神经风格转移</a></h1><div class="content"><h4 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h4><p><strong>神经风格迁移（Neural style transfer）</strong>将参考风格图像的风格“迁移”到另外一张内容图像中，生成具有其特色的图像。</p>
<p><img src="https://hexo-blog-wasim.oss-cn-shenzhen.aliyuncs.com/%E7%A5%9E%E7%BB%8F%E9%A3%8E%E6%A0%BC%E8%BD%AC%E7%A7%BB/Neural-style-transfer.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://github.com/Wasim37/deeplearning-assignment/tree/master/4%20%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/Week4%20%E7%89%B9%E6%AE%8A%E7%9A%84%E5%BA%94%E7%94%A8/Neural%20Style%20Transfer">代码示例</a></li>
<li><a href="https://github.com/Wasim37/fast-style-transfer">fast-style-transfer github项目</a></li>
</ul></div><div class="level is-mobile is-flex"><div class="level-start"><div class="is-uppercase article-more button is-small size-small"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted mr-2" rel="tag" href="/tags/StyleTransfer/">StyleTransfer</a></div></div><div class="level-start"><div class="level-item"><a class="article-more button is-small size-small link-muted" href="/2018/01/27/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/%E7%A5%9E%E7%BB%8F%E9%A3%8E%E6%A0%BC%E8%BD%AC%E7%A7%BB/#more"><i class="fas fa-book-reader has-text-grey"> </i>阅读更多&gt;&gt;</a></div></div></div></article></div><nav class="pagination is-centered mt-4" role="navigation" aria-label="pagination"><div class="pagination-previous is-invisible is-hidden-mobile"><a href="/page/0/">上一页</a></div><div class="pagination-next"><a href="/page/2/">下一页</a></div><ul class="pagination-list is-hidden-mobile"><li><a class="pagination-link is-current" href="/">1</a></li><li><a class="pagination-link" href="/page/2/">2</a></li><li><a class="pagination-link" href="/page/3/">3</a></li></ul></nav></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1 is-sticky"><!--!--><div class="card widget"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="is-rounded" src="https://hexo-blog-wasim.oss-cn-shenzhen.aliyuncs.com/blog_avatar_lufei.png" alt="星空str"></figure><p class="title is-size-4 is-block line-height-inherit">星空str</p><p class="is-size-6 is-block">Developer</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>GuangZhou, China</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="/archives"><p class="title">28</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分类</p><a href="/categories"><p class="title">8</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">标签</p><a href="/tags"><p class="title">23</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/wasim37" target="_blank" rel="noopener">关注我</a></div><div class="level is-mobile"><a class="level-item button is-transparent is-white is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/wasim37"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-white is-marginless" target="_blank" rel="noopener" title="Weibo" href="/"><i class="fab fa-weibo"></i></a><a class="level-item button is-transparent is-white is-marginless" target="_blank" rel="noopener" title="Email" href="/"><i class="fa fa-envelope"></i></a><a class="level-item button is-transparent is-white is-marginless" target="_blank" rel="noopener" title="Next" href="/"><i class="fab fa-dribbble"></i></a><a class="level-item button is-transparent is-white is-marginless" target="_blank" rel="noopener" title="RSS" href="/atom.xml"><i class="fas fa-rss"></i></a></div><hr></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">分类</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/categories/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/"><span class="level-start"><span class="level-item">特征工程</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/"><span class="level-start"><span class="level-item">知识总结</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"><span class="level-start"><span class="level-item">神经网络</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/%E7%BB%8F%E5%85%B8%E6%A8%A1%E5%9E%8B/"><span class="level-start"><span class="level-item">经典模型</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/"><span class="level-start"><span class="level-item">自然语言处理</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"><span class="level-start"><span class="level-item">计算机视觉</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"><span class="level-start"><span class="level-item">论文阅读</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E8%B7%B5/"><span class="level-start"><span class="level-item">项目实践</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></div></div></div><div class="column-right-shadow is-hidden-widescreen"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3"><div class="card widget"><div class="card-content"><h3 class="menu-label">最新评论</h3><span class="body_hot_comment">加载中，最新评论有1分钟延迟...</span></div></div><div class="card widget"><div class="card-content"><h3 class="menu-label">最新文章</h3><article class="media"><div class="media-content size-small"><p><time dateTime="2021-01-01T16:00:00.000Z">2021-01-02</time></p><p class="title is-6"><a class="link-muted" href="/2021/01/02/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">深度学习笔记</a></p><p class="is-uppercase"><i class="fas fa-folder-open has-text-grey"> </i><a class="link-muted" href="/categories/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/">知识总结</a></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2021-01-01T16:00:00.000Z">2021-01-02</time></p><p class="title is-6"><a class="link-muted" href="/2021/01/02/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">其他</a></p><p class="is-uppercase"><i class="fas fa-folder-open has-text-grey"> </i><a class="link-muted" href="/categories/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/">知识总结</a></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2021-01-01T14:22:00.000Z">2021-01-01</time></p><p class="title is-6"><a class="link-muted" href="/2021/01/01/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">机器学习笔记</a></p><p class="is-uppercase"><i class="fas fa-folder-open has-text-grey"> </i><a class="link-muted" href="/categories/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/">知识总结</a></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2020-04-10T16:00:00.000Z">2020-04-11</time></p><p class="title is-6"><a class="link-muted" href="/2020/04/11/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/%E4%BB%8ENB%E5%88%B0%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/">从NB到语言模型</a></p><p class="is-uppercase"><i class="fas fa-folder-open has-text-grey"> </i><a class="link-muted" href="/categories/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/">自然语言处理</a></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2020-04-10T16:00:00.000Z">2020-04-11</time></p><p class="title is-6"><a class="link-muted" href="/2020/04/11/%E7%BB%8F%E5%85%B8%E6%A8%A1%E5%9E%8B/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF/">朴素贝叶斯</a></p><p class="is-uppercase"><i class="fas fa-folder-open has-text-grey"> </i><a class="link-muted" href="/categories/%E7%BB%8F%E5%85%B8%E6%A8%A1%E5%9E%8B/">经典模型</a></p></div></article></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">归档</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/archives/2021/01/"><span class="level-start"><span class="level-item">一月 2021</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2020/04/"><span class="level-start"><span class="level-item">四月 2020</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2018/07/"><span class="level-start"><span class="level-item">七月 2018</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2018/03/"><span class="level-start"><span class="level-item">三月 2018</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2018/02/"><span class="level-start"><span class="level-item">二月 2018</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><a class="level is-mobile is-marginless" href="/archives/"><span class="level-start"><span class="level-item">查看全部&gt;&gt;</span></span></a></ul></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">标签</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/%E8%B4%9D%E5%8F%B6%E6%96%AF/"><span class="tag">贝叶斯</span><span class="tag is-grey-lightest">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CNN/"><span class="tag">CNN</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"><span class="tag">机器学习</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/RNN/"><span class="tag">RNN</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%8F%90%E5%8D%87%E7%AE%97%E6%B3%95/"><span class="tag">提升算法</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/StyleTransfer/"><span class="tag">StyleTransfer</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/YOLO/"><span class="tag">YOLO</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/word2vec/"><span class="tag">word2vec</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/"><span class="tag">人脸识别</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%86%B3%E7%AD%96%E6%A0%91/"><span class="tag">决策树</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%8D%B7%E7%A7%AF/"><span class="tag">卷积</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/KNN/"><span class="tag">KNN</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Attention-Model/"><span class="tag">Attention Model</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"><span class="tag">深度学习</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/"><span class="tag">特征工程</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%9F%A5%E8%AF%86%E8%BF%BD%E8%B8%AA/"><span class="tag">知识追踪</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"><span class="tag">线性回归</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%81%9A%E7%B1%BB/"><span class="tag">聚类</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/SVM/"><span class="tag">SVM</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%BE%B9%E7%BC%98%E6%A3%80%E6%B5%8B/"><span class="tag">边缘检测</span><span class="tag is-grey-lightest">1</span></a></div></div><div class="field is-grouped is-grouped-multiline"><a class="tags has-addons" href="/tags/"><span class="tag">查看全部&gt;&gt;</span></a></div></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="https://hexo-blog-wasim.oss-cn-shenzhen.aliyuncs.com/logo.svg" alt="星空str" height="28"></a><p class="size-small"><span>&copy; 2020 wasim37</span>  Powered by <a href="https://hexo.io/" target="_blank">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/wasim37"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script>moment.locale("zh-CN");</script><script>var IcarusThemeSettings = {
            site: {
                url: 'http://wangxin123.com',
                external_link: {"enable":true,"exclude":[]}
            },
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back-to-top.js" defer></script><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script src="/js/gallery.js" defer></script><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" defer></script><script>document.addEventListener("DOMContentLoaded", function() {
            document.querySelectorAll('[role="article"] > .content').forEach(function(element) {
                renderMathInElement(element);
            });
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            MathJax.Hub.Config({
                'HTML-CSS': {
                    matchFontHeight: false
                },
                SVG: {
                    matchFontHeight: false
                },
                CommonHTML: {
                    matchFontHeight: false
                },
                tex2jax: {
                    inlineMath: [
                        ['$','$'],
                        ['\\(','\\)']
                    ]
                }
            });
        });</script><!--!--><script src="/js/main.js" defer></script><script src="/js/comment-issue-data.js" defer></script><link rel="stylesheet" href="/css/insight.css"><div class="searchbox ins-search"><div class="searchbox-container ins-search-container"><div class="searchbox-input-wrapper"><input class="searchbox-input ins-search-input" type="text" placeholder="想要查找什么..."><span class="searchbox-close ins-close ins-selectable"><i class="fa fa-times-circle"></i></span></div><div class="searchbox-result-wrapper ins-section-wrapper"><div class="ins-section-container"></div></div></div></div><script>(function (window) {
            var INSIGHT_CONFIG = {
                TRANSLATION: {
                    POSTS: '文章',
                    PAGES: '页面',
                    CATEGORIES: '分类',
                    TAGS: '标签',
                    UNTITLED: '(无标题)',
                },
                CONTENT_URL: '/content.json',
            };
            window.INSIGHT_CONFIG = INSIGHT_CONFIG;
        })(window);</script><script src="/js/insight.js" defer></script></body></html>